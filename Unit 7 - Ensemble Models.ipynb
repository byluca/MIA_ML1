{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5dd4668",
   "metadata": {},
   "source": [
    "# Ensemble Models\n",
    "\n",
    "One of the latest trends in artificial intelligence modelling can be summarised as \"knowledge of the whole or the crowd\". What this somewhat familiar phrase defines is the use of a multitude of so-called \"weak\" models in a meta-classifier. The aim is to generate a \"strong\" model based on the knowledge extracted by the \"weak\" models. For example, although it will be detailed later, multiple, much simpler Decision Trees are developed in a Random Forest. The combination of these ones in the Random Forest exceeds the performance of any of the individual models. The models that emerge in this way, as meta-classifiers or meta-regressors, are generically called **Ensemble models**.\n",
    "\n",
    "Is is worth mentioned that these models may not be limited only to decision trees, but may instead be composed of any type of machine learning model that has been seen previously. They can even be mixed models where not all models have been obtained in the same way, but can be created through the combined use of several techniques such as K-NN, SVM, etc. Thus, the first criteria to classifify the ensemble models would be if they are homogeneous or heterogeneous models. However this is not the only criteria to classifity the ensemble models, in this unit, we will explore various ways of generating the models and how to combine them later on. We will also take a closer look at two of the most common techniques within ensemble models such as Random Forest and _XGBoost_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f73db",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Unlike the first tutorials, where the iris flower problem has been used as a benchmark, in this tutorial we will use a different one. The problem is also included in the UCI repository, although it is also small, the number of variables increases significantly and therefore it will give us some more room to explore. Specifically, it is a classic machine learning problem, which is informally called Rock or Mine? It is a small database consisting of 111 patterns corresponding to rocks and 97 to water mines (simulated as metal cylinders). Each of the patterns consists of 60 numerical measurements corresponding to a section of the sonar sequences. These values are already between 0.0 and 1.0, although it is worth normalising them to be on the safe side. These measurements represent the energy value of different wavelength ranges for a certain period of time.\n",
    "\n",
    "We are going to use a couple of new packages in the process, more specificly, [DataFrames.jl](https://juliaai.github.io/DataScienceTutorials.jl/data/dataframe/) and [UrlDownload.jl](https://github.com/Arkoniak/UrlDownload.jl). Therefore, first thing first, ensure that the packages are correcly installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0eb88ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg;\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"UrlDownload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad05475",
   "metadata": {},
   "source": [
    "After that, the data will be downloaded if they are not already available, for which the following code can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "007c0232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>61×7 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">36 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">variable</th><th style = \"text-align: left;\">mean</th><th style = \"text-align: left;\">min</th><th style = \"text-align: left;\">median</th><th style = \"text-align: left;\">max</th><th style = \"text-align: left;\">nmissing</th><th style = \"text-align: left;\">eltype</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Symbol\" style = \"text-align: left;\">Symbol</th><th title = \"Union{Nothing, Float64}\" style = \"text-align: left;\">Union…</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Union{Nothing, Float64}\" style = \"text-align: left;\">Union…</th><th title = \"Any\" style = \"text-align: left;\">Any</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"DataType\" style = \"text-align: left;\">DataType</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">Column1</td><td style = \"text-align: left;\">0.0291639</td><td style = \"text-align: left;\">0.0015</td><td style = \"text-align: left;\">0.0228</td><td style = \"text-align: left;\">0.1371</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">Column2</td><td style = \"text-align: left;\">0.0384365</td><td style = \"text-align: left;\">0.0006</td><td style = \"text-align: left;\">0.0308</td><td style = \"text-align: left;\">0.2339</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">Column3</td><td style = \"text-align: left;\">0.0438322</td><td style = \"text-align: left;\">0.0015</td><td style = \"text-align: left;\">0.0343</td><td style = \"text-align: left;\">0.3059</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">Column4</td><td style = \"text-align: left;\">0.0538923</td><td style = \"text-align: left;\">0.0058</td><td style = \"text-align: left;\">0.04405</td><td style = \"text-align: left;\">0.4264</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">Column5</td><td style = \"text-align: left;\">0.0752024</td><td style = \"text-align: left;\">0.0067</td><td style = \"text-align: left;\">0.0625</td><td style = \"text-align: left;\">0.401</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">Column6</td><td style = \"text-align: left;\">0.10457</td><td style = \"text-align: left;\">0.0102</td><td style = \"text-align: left;\">0.09215</td><td style = \"text-align: left;\">0.3823</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">Column7</td><td style = \"text-align: left;\">0.121747</td><td style = \"text-align: left;\">0.0033</td><td style = \"text-align: left;\">0.10695</td><td style = \"text-align: left;\">0.3729</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">Column8</td><td style = \"text-align: left;\">0.134799</td><td style = \"text-align: left;\">0.0055</td><td style = \"text-align: left;\">0.1121</td><td style = \"text-align: left;\">0.459</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">Column9</td><td style = \"text-align: left;\">0.178003</td><td style = \"text-align: left;\">0.0075</td><td style = \"text-align: left;\">0.15225</td><td style = \"text-align: left;\">0.6828</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">Column10</td><td style = \"text-align: left;\">0.208259</td><td style = \"text-align: left;\">0.0113</td><td style = \"text-align: left;\">0.1824</td><td style = \"text-align: left;\">0.7106</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: left;\">Column11</td><td style = \"text-align: left;\">0.236013</td><td style = \"text-align: left;\">0.0289</td><td style = \"text-align: left;\">0.2248</td><td style = \"text-align: left;\">0.7342</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: left;\">Column12</td><td style = \"text-align: left;\">0.250221</td><td style = \"text-align: left;\">0.0236</td><td style = \"text-align: left;\">0.24905</td><td style = \"text-align: left;\">0.706</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: left;\">Column13</td><td style = \"text-align: left;\">0.273305</td><td style = \"text-align: left;\">0.0184</td><td style = \"text-align: left;\">0.26395</td><td style = \"text-align: left;\">0.7131</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">50</td><td style = \"text-align: left;\">Column50</td><td style = \"text-align: left;\">0.020424</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">0.0179</td><td style = \"text-align: left;\">0.0825</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">51</td><td style = \"text-align: left;\">Column51</td><td style = \"text-align: left;\">0.0160687</td><td style = \"text-align: left;\">0.0</td><td style = \"text-align: left;\">0.0139</td><td style = \"text-align: left;\">0.1004</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">52</td><td style = \"text-align: left;\">Column52</td><td style = \"text-align: left;\">0.0134202</td><td style = \"text-align: left;\">0.0008</td><td style = \"text-align: left;\">0.0114</td><td style = \"text-align: left;\">0.0709</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">53</td><td style = \"text-align: left;\">Column53</td><td style = \"text-align: left;\">0.0107091</td><td style = \"text-align: left;\">0.0005</td><td style = \"text-align: left;\">0.00955</td><td style = \"text-align: left;\">0.039</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54</td><td style = \"text-align: left;\">Column54</td><td style = \"text-align: left;\">0.0109409</td><td style = \"text-align: left;\">0.001</td><td style = \"text-align: left;\">0.0093</td><td style = \"text-align: left;\">0.0352</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">55</td><td style = \"text-align: left;\">Column55</td><td style = \"text-align: left;\">0.00929038</td><td style = \"text-align: left;\">0.0006</td><td style = \"text-align: left;\">0.0075</td><td style = \"text-align: left;\">0.0447</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">56</td><td style = \"text-align: left;\">Column56</td><td style = \"text-align: left;\">0.00822163</td><td style = \"text-align: left;\">0.0004</td><td style = \"text-align: left;\">0.00685</td><td style = \"text-align: left;\">0.0394</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">57</td><td style = \"text-align: left;\">Column57</td><td style = \"text-align: left;\">0.00782019</td><td style = \"text-align: left;\">0.0003</td><td style = \"text-align: left;\">0.00595</td><td style = \"text-align: left;\">0.0355</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">58</td><td style = \"text-align: left;\">Column58</td><td style = \"text-align: left;\">0.00794904</td><td style = \"text-align: left;\">0.0003</td><td style = \"text-align: left;\">0.0058</td><td style = \"text-align: left;\">0.044</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">59</td><td style = \"text-align: left;\">Column59</td><td style = \"text-align: left;\">0.00794135</td><td style = \"text-align: left;\">0.0001</td><td style = \"text-align: left;\">0.0064</td><td style = \"text-align: left;\">0.0364</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">60</td><td style = \"text-align: left;\">Column60</td><td style = \"text-align: left;\">0.00650721</td><td style = \"text-align: left;\">0.0006</td><td style = \"text-align: left;\">0.0053</td><td style = \"text-align: left;\">0.0439</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">Float64</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">61</td><td style = \"text-align: left;\">Column61</td><td style = \"text-align: left;\"></td><td style = \"text-align: left;\">M</td><td style = \"text-align: left;\"></td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">0</td><td style = \"text-align: left;\">String1</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & Column1 & 0.0291639 & 0.0015 & 0.0228 & 0.1371 & 0 & Float64 \\\\\n",
       "\t2 & Column2 & 0.0384365 & 0.0006 & 0.0308 & 0.2339 & 0 & Float64 \\\\\n",
       "\t3 & Column3 & 0.0438322 & 0.0015 & 0.0343 & 0.3059 & 0 & Float64 \\\\\n",
       "\t4 & Column4 & 0.0538923 & 0.0058 & 0.04405 & 0.4264 & 0 & Float64 \\\\\n",
       "\t5 & Column5 & 0.0752024 & 0.0067 & 0.0625 & 0.401 & 0 & Float64 \\\\\n",
       "\t6 & Column6 & 0.10457 & 0.0102 & 0.09215 & 0.3823 & 0 & Float64 \\\\\n",
       "\t7 & Column7 & 0.121747 & 0.0033 & 0.10695 & 0.3729 & 0 & Float64 \\\\\n",
       "\t8 & Column8 & 0.134799 & 0.0055 & 0.1121 & 0.459 & 0 & Float64 \\\\\n",
       "\t9 & Column9 & 0.178003 & 0.0075 & 0.15225 & 0.6828 & 0 & Float64 \\\\\n",
       "\t10 & Column10 & 0.208259 & 0.0113 & 0.1824 & 0.7106 & 0 & Float64 \\\\\n",
       "\t11 & Column11 & 0.236013 & 0.0289 & 0.2248 & 0.7342 & 0 & Float64 \\\\\n",
       "\t12 & Column12 & 0.250221 & 0.0236 & 0.24905 & 0.706 & 0 & Float64 \\\\\n",
       "\t13 & Column13 & 0.273305 & 0.0184 & 0.26395 & 0.7131 & 0 & Float64 \\\\\n",
       "\t14 & Column14 & 0.296568 & 0.0273 & 0.2811 & 0.997 & 0 & Float64 \\\\\n",
       "\t15 & Column15 & 0.320201 & 0.0031 & 0.2817 & 1.0 & 0 & Float64 \\\\\n",
       "\t16 & Column16 & 0.378487 & 0.0162 & 0.3047 & 0.9988 & 0 & Float64 \\\\\n",
       "\t17 & Column17 & 0.415983 & 0.0349 & 0.3084 & 1.0 & 0 & Float64 \\\\\n",
       "\t18 & Column18 & 0.452318 & 0.0375 & 0.3683 & 1.0 & 0 & Float64 \\\\\n",
       "\t19 & Column19 & 0.504812 & 0.0494 & 0.43495 & 1.0 & 0 & Float64 \\\\\n",
       "\t20 & Column20 & 0.563047 & 0.0656 & 0.5425 & 1.0 & 0 & Float64 \\\\\n",
       "\t21 & Column21 & 0.60906 & 0.0512 & 0.6177 & 1.0 & 0 & Float64 \\\\\n",
       "\t22 & Column22 & 0.624275 & 0.0219 & 0.6649 & 1.0 & 0 & Float64 \\\\\n",
       "\t23 & Column23 & 0.646975 & 0.0563 & 0.6997 & 1.0 & 0 & Float64 \\\\\n",
       "\t24 & Column24 & 0.672654 & 0.0239 & 0.6985 & 1.0 & 0 & Float64 \\\\\n",
       "\t25 & Column25 & 0.675424 & 0.024 & 0.7211 & 1.0 & 0 & Float64 \\\\\n",
       "\t26 & Column26 & 0.699866 & 0.0921 & 0.7545 & 1.0 & 0 & Float64 \\\\\n",
       "\t27 & Column27 & 0.702155 & 0.0481 & 0.7456 & 1.0 & 0 & Float64 \\\\\n",
       "\t28 & Column28 & 0.694024 & 0.0284 & 0.7319 & 1.0 & 0 & Float64 \\\\\n",
       "\t29 & Column29 & 0.642074 & 0.0144 & 0.6808 & 1.0 & 0 & Float64 \\\\\n",
       "\t30 & Column30 & 0.580928 & 0.0613 & 0.60715 & 1.0 & 0 & Float64 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m61×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable \u001b[0m\u001b[1m mean       \u001b[0m\u001b[1m min    \u001b[0m\u001b[1m median  \u001b[0m\u001b[1m max    \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype   \u001b[0m\n",
       "     │\u001b[90m Symbol   \u001b[0m\u001b[90m Union…     \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Union…  \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m DataType \u001b[0m\n",
       "─────┼───────────────────────────────────────────────────────────────────\n",
       "   1 │ Column1   0.0291639   0.0015  0.0228   0.1371         0  Float64\n",
       "   2 │ Column2   0.0384365   0.0006  0.0308   0.2339         0  Float64\n",
       "   3 │ Column3   0.0438322   0.0015  0.0343   0.3059         0  Float64\n",
       "   4 │ Column4   0.0538923   0.0058  0.04405  0.4264         0  Float64\n",
       "   5 │ Column5   0.0752024   0.0067  0.0625   0.401          0  Float64\n",
       "   6 │ Column6   0.10457     0.0102  0.09215  0.3823         0  Float64\n",
       "   7 │ Column7   0.121747    0.0033  0.10695  0.3729         0  Float64\n",
       "   8 │ Column8   0.134799    0.0055  0.1121   0.459          0  Float64\n",
       "   9 │ Column9   0.178003    0.0075  0.15225  0.6828         0  Float64\n",
       "  10 │ Column10  0.208259    0.0113  0.1824   0.7106         0  Float64\n",
       "  11 │ Column11  0.236013    0.0289  0.2248   0.7342         0  Float64\n",
       "  ⋮  │    ⋮          ⋮         ⋮        ⋮       ⋮        ⋮         ⋮\n",
       "  52 │ Column52  0.0134202   0.0008  0.0114   0.0709         0  Float64\n",
       "  53 │ Column53  0.0107091   0.0005  0.00955  0.039          0  Float64\n",
       "  54 │ Column54  0.0109409   0.001   0.0093   0.0352         0  Float64\n",
       "  55 │ Column55  0.00929038  0.0006  0.0075   0.0447         0  Float64\n",
       "  56 │ Column56  0.00822163  0.0004  0.00685  0.0394         0  Float64\n",
       "  57 │ Column57  0.00782019  0.0003  0.00595  0.0355         0  Float64\n",
       "  58 │ Column58  0.00794904  0.0003  0.0058   0.044          0  Float64\n",
       "  59 │ Column59  0.00794135  0.0001  0.0064   0.0364         0  Float64\n",
       "  60 │ Column60  0.00650721  0.0006  0.0053   0.0439         0  Float64\n",
       "  61 │ Column61 \u001b[90m            \u001b[0m M      \u001b[90m         \u001b[0m R              0  String1\n",
       "\u001b[36m                                                          40 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using UrlDownload\n",
    "using DataFrames\n",
    "using CSV\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\"\n",
    "data = urldownload(url, true, format=:CSV, header=false) |> DataFrame\n",
    "describe(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebf504",
   "metadata": {},
   "source": [
    "As it can be seen in the previos line, we have downloaded de data and pipe it, with the operator `|>`, into the function DataFrame. This is going to create an structure simular to a database table which is particular convinient to check for missing values or the ranges of the different variables. In fact, the library makes it particularly easy to deal with missing values with functions to fullfill or remove the samples with non-valid measures. However it is too long to see every single variable on the output report, if some queries are made we can identify  that here is no missing values. Additionally no variable is over 1.0 but some of them are not normalized. A similar structure can be found in other languages, like R or Python.\n",
    "\n",
    "As an example, of this process lets make the an additional column in order to convert to categorical the las column 60 which has a **M** for each Mine and an **R** for each sample of rock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a07ecb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>208×62 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">183 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Column1</th><th style = \"text-align: left;\">Column2</th><th style = \"text-align: left;\">Column3</th><th style = \"text-align: left;\">Column4</th><th style = \"text-align: left;\">Column5</th><th style = \"text-align: left;\">Column6</th><th style = \"text-align: left;\">Column7</th><th style = \"text-align: left;\">Column8</th><th style = \"text-align: left;\">Column9</th><th style = \"text-align: left;\">Column10</th><th style = \"text-align: left;\">Column11</th><th style = \"text-align: left;\">Column12</th><th style = \"text-align: left;\">Column13</th><th style = \"text-align: left;\">Column14</th><th style = \"text-align: left;\">Column15</th><th style = \"text-align: left;\">Column16</th><th style = \"text-align: left;\">Column17</th><th style = \"text-align: left;\">Column18</th><th style = \"text-align: left;\">Column19</th><th style = \"text-align: left;\">Column20</th><th style = \"text-align: left;\">Column21</th><th style = \"text-align: left;\">Column22</th><th style = \"text-align: left;\">Column23</th><th style = \"text-align: left;\">Column24</th><th style = \"text-align: left;\">Column25</th><th style = \"text-align: left;\">Column26</th><th style = \"text-align: left;\">Column27</th><th style = \"text-align: left;\">Column28</th><th style = \"text-align: left;\">Column29</th><th style = \"text-align: left;\">Column30</th><th style = \"text-align: left;\">Column31</th><th style = \"text-align: left;\">Column32</th><th style = \"text-align: left;\">Column33</th><th style = \"text-align: left;\">Column34</th><th style = \"text-align: left;\">Column35</th><th style = \"text-align: left;\">Column36</th><th style = \"text-align: left;\">Column37</th><th style = \"text-align: left;\">Column38</th><th style = \"text-align: left;\">Column39</th><th style = \"text-align: left;\">Column40</th><th style = \"text-align: left;\">Column41</th><th style = \"text-align: left;\">Column42</th><th style = \"text-align: left;\">Column43</th><th style = \"text-align: left;\">Column44</th><th style = \"text-align: left;\">Column45</th><th style = \"text-align: left;\">Column46</th><th style = \"text-align: left;\">Column47</th><th style = \"text-align: left;\">Column48</th><th style = \"text-align: left;\">Column49</th><th style = \"text-align: left;\">Column50</th><th style = \"text-align: left;\">Column51</th><th style = \"text-align: left;\">Column52</th><th style = \"text-align: left;\">Column53</th><th style = \"text-align: left;\">Column54</th><th style = \"text-align: left;\">Column55</th><th style = \"text-align: left;\">Column56</th><th style = \"text-align: left;\">Column57</th><th style = \"text-align: left;\">Column58</th><th style = \"text-align: left;\">Column59</th><th style = \"text-align: left;\">Column60</th><th style = \"text-align: left;\">Column61</th><th style = \"text-align: left;\">Mine</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String1\" style = \"text-align: left;\">String1</th><th title = \"Bool\" style = \"text-align: left;\">Bool</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">0.02</td><td style = \"text-align: right;\">0.0371</td><td style = \"text-align: right;\">0.0428</td><td style = \"text-align: right;\">0.0207</td><td style = \"text-align: right;\">0.0954</td><td style = \"text-align: right;\">0.0986</td><td style = \"text-align: right;\">0.1539</td><td style = \"text-align: right;\">0.1601</td><td style = \"text-align: right;\">0.3109</td><td style = \"text-align: right;\">0.2111</td><td style = \"text-align: right;\">0.1609</td><td style = \"text-align: right;\">0.1582</td><td style = \"text-align: right;\">0.2238</td><td style = \"text-align: right;\">0.0645</td><td style = \"text-align: right;\">0.066</td><td style = \"text-align: right;\">0.2273</td><td style = \"text-align: right;\">0.31</td><td style = \"text-align: right;\">0.2999</td><td style = \"text-align: right;\">0.5078</td><td style = \"text-align: right;\">0.4797</td><td style = \"text-align: right;\">0.5783</td><td style = \"text-align: right;\">0.5071</td><td style = \"text-align: right;\">0.4328</td><td style = \"text-align: right;\">0.555</td><td style = \"text-align: right;\">0.6711</td><td style = \"text-align: right;\">0.6415</td><td style = \"text-align: right;\">0.7104</td><td style = \"text-align: right;\">0.808</td><td style = \"text-align: right;\">0.6791</td><td style = \"text-align: right;\">0.3857</td><td style = \"text-align: right;\">0.1307</td><td style = \"text-align: right;\">0.2604</td><td style = \"text-align: right;\">0.5121</td><td style = \"text-align: right;\">0.7547</td><td style = \"text-align: right;\">0.8537</td><td style = \"text-align: right;\">0.8507</td><td style = \"text-align: right;\">0.6692</td><td style = \"text-align: right;\">0.6097</td><td style = \"text-align: right;\">0.4943</td><td style = \"text-align: right;\">0.2744</td><td style = \"text-align: right;\">0.051</td><td style = \"text-align: right;\">0.2834</td><td style = \"text-align: right;\">0.2825</td><td style = \"text-align: right;\">0.4256</td><td style = \"text-align: right;\">0.2641</td><td style = \"text-align: right;\">0.1386</td><td style = \"text-align: right;\">0.1051</td><td style = \"text-align: right;\">0.1343</td><td style = \"text-align: right;\">0.0383</td><td style = \"text-align: right;\">0.0324</td><td style = \"text-align: right;\">0.0232</td><td style = \"text-align: right;\">0.0027</td><td style = \"text-align: right;\">0.0065</td><td style = \"text-align: right;\">0.0159</td><td style = \"text-align: right;\">0.0072</td><td style = \"text-align: right;\">0.0167</td><td style = \"text-align: right;\">0.018</td><td style = \"text-align: right;\">0.0084</td><td style = \"text-align: right;\">0.009</td><td style = \"text-align: right;\">0.0032</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">0.0453</td><td style = \"text-align: right;\">0.0523</td><td style = \"text-align: right;\">0.0843</td><td style = \"text-align: right;\">0.0689</td><td style = \"text-align: right;\">0.1183</td><td style = \"text-align: right;\">0.2583</td><td style = \"text-align: right;\">0.2156</td><td style = \"text-align: right;\">0.3481</td><td style = \"text-align: right;\">0.3337</td><td style = \"text-align: right;\">0.2872</td><td style = \"text-align: right;\">0.4918</td><td style = \"text-align: right;\">0.6552</td><td style = \"text-align: right;\">0.6919</td><td style = \"text-align: right;\">0.7797</td><td style = \"text-align: right;\">0.7464</td><td style = \"text-align: right;\">0.9444</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.8874</td><td style = \"text-align: right;\">0.8024</td><td style = \"text-align: right;\">0.7818</td><td style = \"text-align: right;\">0.5212</td><td style = \"text-align: right;\">0.4052</td><td style = \"text-align: right;\">0.3957</td><td style = \"text-align: right;\">0.3914</td><td style = \"text-align: right;\">0.325</td><td style = \"text-align: right;\">0.32</td><td style = \"text-align: right;\">0.3271</td><td style = \"text-align: right;\">0.2767</td><td style = \"text-align: right;\">0.4423</td><td style = \"text-align: right;\">0.2028</td><td style = \"text-align: right;\">0.3788</td><td style = \"text-align: right;\">0.2947</td><td style = \"text-align: right;\">0.1984</td><td style = \"text-align: right;\">0.2341</td><td style = \"text-align: right;\">0.1306</td><td style = \"text-align: right;\">0.4182</td><td style = \"text-align: right;\">0.3835</td><td style = \"text-align: right;\">0.1057</td><td style = \"text-align: right;\">0.184</td><td style = \"text-align: right;\">0.197</td><td style = \"text-align: right;\">0.1674</td><td style = \"text-align: right;\">0.0583</td><td style = \"text-align: right;\">0.1401</td><td style = \"text-align: right;\">0.1628</td><td style = \"text-align: right;\">0.0621</td><td style = \"text-align: right;\">0.0203</td><td style = \"text-align: right;\">0.053</td><td style = \"text-align: right;\">0.0742</td><td style = \"text-align: right;\">0.0409</td><td style = \"text-align: right;\">0.0061</td><td style = \"text-align: right;\">0.0125</td><td style = \"text-align: right;\">0.0084</td><td style = \"text-align: right;\">0.0089</td><td style = \"text-align: right;\">0.0048</td><td style = \"text-align: right;\">0.0094</td><td style = \"text-align: right;\">0.0191</td><td style = \"text-align: right;\">0.014</td><td style = \"text-align: right;\">0.0049</td><td style = \"text-align: right;\">0.0052</td><td style = \"text-align: right;\">0.0044</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">0.0262</td><td style = \"text-align: right;\">0.0582</td><td style = \"text-align: right;\">0.1099</td><td style = \"text-align: right;\">0.1083</td><td style = \"text-align: right;\">0.0974</td><td style = \"text-align: right;\">0.228</td><td style = \"text-align: right;\">0.2431</td><td style = \"text-align: right;\">0.3771</td><td style = \"text-align: right;\">0.5598</td><td style = \"text-align: right;\">0.6194</td><td style = \"text-align: right;\">0.6333</td><td style = \"text-align: right;\">0.706</td><td style = \"text-align: right;\">0.5544</td><td style = \"text-align: right;\">0.532</td><td style = \"text-align: right;\">0.6479</td><td style = \"text-align: right;\">0.6931</td><td style = \"text-align: right;\">0.6759</td><td style = \"text-align: right;\">0.7551</td><td style = \"text-align: right;\">0.8929</td><td style = \"text-align: right;\">0.8619</td><td style = \"text-align: right;\">0.7974</td><td style = \"text-align: right;\">0.6737</td><td style = \"text-align: right;\">0.4293</td><td style = \"text-align: right;\">0.3648</td><td style = \"text-align: right;\">0.5331</td><td style = \"text-align: right;\">0.2413</td><td style = \"text-align: right;\">0.507</td><td style = \"text-align: right;\">0.8533</td><td style = \"text-align: right;\">0.6036</td><td style = \"text-align: right;\">0.8514</td><td style = \"text-align: right;\">0.8512</td><td style = \"text-align: right;\">0.5045</td><td style = \"text-align: right;\">0.1862</td><td style = \"text-align: right;\">0.2709</td><td style = \"text-align: right;\">0.4232</td><td style = \"text-align: right;\">0.3043</td><td style = \"text-align: right;\">0.6116</td><td style = \"text-align: right;\">0.6756</td><td style = \"text-align: right;\">0.5375</td><td style = \"text-align: right;\">0.4719</td><td style = \"text-align: right;\">0.4647</td><td style = \"text-align: right;\">0.2587</td><td style = \"text-align: right;\">0.2129</td><td style = \"text-align: right;\">0.2222</td><td style = \"text-align: right;\">0.2111</td><td style = \"text-align: right;\">0.0176</td><td style = \"text-align: right;\">0.1348</td><td style = \"text-align: right;\">0.0744</td><td style = \"text-align: right;\">0.013</td><td style = \"text-align: right;\">0.0106</td><td style = \"text-align: right;\">0.0033</td><td style = \"text-align: right;\">0.0232</td><td style = \"text-align: right;\">0.0166</td><td style = \"text-align: right;\">0.0095</td><td style = \"text-align: right;\">0.018</td><td style = \"text-align: right;\">0.0244</td><td style = \"text-align: right;\">0.0316</td><td style = \"text-align: right;\">0.0164</td><td style = \"text-align: right;\">0.0095</td><td style = \"text-align: right;\">0.0078</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">0.01</td><td style = \"text-align: right;\">0.0171</td><td style = \"text-align: right;\">0.0623</td><td style = \"text-align: right;\">0.0205</td><td style = \"text-align: right;\">0.0205</td><td style = \"text-align: right;\">0.0368</td><td style = \"text-align: right;\">0.1098</td><td style = \"text-align: right;\">0.1276</td><td style = \"text-align: right;\">0.0598</td><td style = \"text-align: right;\">0.1264</td><td style = \"text-align: right;\">0.0881</td><td style = \"text-align: right;\">0.1992</td><td style = \"text-align: right;\">0.0184</td><td style = \"text-align: right;\">0.2261</td><td style = \"text-align: right;\">0.1729</td><td style = \"text-align: right;\">0.2131</td><td style = \"text-align: right;\">0.0693</td><td style = \"text-align: right;\">0.2281</td><td style = \"text-align: right;\">0.406</td><td style = \"text-align: right;\">0.3973</td><td style = \"text-align: right;\">0.2741</td><td style = \"text-align: right;\">0.369</td><td style = \"text-align: right;\">0.5556</td><td style = \"text-align: right;\">0.4846</td><td style = \"text-align: right;\">0.314</td><td style = \"text-align: right;\">0.5334</td><td style = \"text-align: right;\">0.5256</td><td style = \"text-align: right;\">0.252</td><td style = \"text-align: right;\">0.209</td><td style = \"text-align: right;\">0.3559</td><td style = \"text-align: right;\">0.626</td><td style = \"text-align: right;\">0.734</td><td style = \"text-align: right;\">0.612</td><td style = \"text-align: right;\">0.3497</td><td style = \"text-align: right;\">0.3953</td><td style = \"text-align: right;\">0.3012</td><td style = \"text-align: right;\">0.5408</td><td style = \"text-align: right;\">0.8814</td><td style = \"text-align: right;\">0.9857</td><td style = \"text-align: right;\">0.9167</td><td style = \"text-align: right;\">0.6121</td><td style = \"text-align: right;\">0.5006</td><td style = \"text-align: right;\">0.321</td><td style = \"text-align: right;\">0.3202</td><td style = \"text-align: right;\">0.4295</td><td style = \"text-align: right;\">0.3654</td><td style = \"text-align: right;\">0.2655</td><td style = \"text-align: right;\">0.1576</td><td style = \"text-align: right;\">0.0681</td><td style = \"text-align: right;\">0.0294</td><td style = \"text-align: right;\">0.0241</td><td style = \"text-align: right;\">0.0121</td><td style = \"text-align: right;\">0.0036</td><td style = \"text-align: right;\">0.015</td><td style = \"text-align: right;\">0.0085</td><td style = \"text-align: right;\">0.0073</td><td style = \"text-align: right;\">0.005</td><td style = \"text-align: right;\">0.0044</td><td style = \"text-align: right;\">0.004</td><td style = \"text-align: right;\">0.0117</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">0.0762</td><td style = \"text-align: right;\">0.0666</td><td style = \"text-align: right;\">0.0481</td><td style = \"text-align: right;\">0.0394</td><td style = \"text-align: right;\">0.059</td><td style = \"text-align: right;\">0.0649</td><td style = \"text-align: right;\">0.1209</td><td style = \"text-align: right;\">0.2467</td><td style = \"text-align: right;\">0.3564</td><td style = \"text-align: right;\">0.4459</td><td style = \"text-align: right;\">0.4152</td><td style = \"text-align: right;\">0.3952</td><td style = \"text-align: right;\">0.4256</td><td style = \"text-align: right;\">0.4135</td><td style = \"text-align: right;\">0.4528</td><td style = \"text-align: right;\">0.5326</td><td style = \"text-align: right;\">0.7306</td><td style = \"text-align: right;\">0.6193</td><td style = \"text-align: right;\">0.2032</td><td style = \"text-align: right;\">0.4636</td><td style = \"text-align: right;\">0.4148</td><td style = \"text-align: right;\">0.4292</td><td style = \"text-align: right;\">0.573</td><td style = \"text-align: right;\">0.5399</td><td style = \"text-align: right;\">0.3161</td><td style = \"text-align: right;\">0.2285</td><td style = \"text-align: right;\">0.6995</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.7262</td><td style = \"text-align: right;\">0.4724</td><td style = \"text-align: right;\">0.5103</td><td style = \"text-align: right;\">0.5459</td><td style = \"text-align: right;\">0.2881</td><td style = \"text-align: right;\">0.0981</td><td style = \"text-align: right;\">0.1951</td><td style = \"text-align: right;\">0.4181</td><td style = \"text-align: right;\">0.4604</td><td style = \"text-align: right;\">0.3217</td><td style = \"text-align: right;\">0.2828</td><td style = \"text-align: right;\">0.243</td><td style = \"text-align: right;\">0.1979</td><td style = \"text-align: right;\">0.2444</td><td style = \"text-align: right;\">0.1847</td><td style = \"text-align: right;\">0.0841</td><td style = \"text-align: right;\">0.0692</td><td style = \"text-align: right;\">0.0528</td><td style = \"text-align: right;\">0.0357</td><td style = \"text-align: right;\">0.0085</td><td style = \"text-align: right;\">0.023</td><td style = \"text-align: right;\">0.0046</td><td style = \"text-align: right;\">0.0156</td><td style = \"text-align: right;\">0.0031</td><td style = \"text-align: right;\">0.0054</td><td style = \"text-align: right;\">0.0105</td><td style = \"text-align: right;\">0.011</td><td style = \"text-align: right;\">0.0015</td><td style = \"text-align: right;\">0.0072</td><td style = \"text-align: right;\">0.0048</td><td style = \"text-align: right;\">0.0107</td><td style = \"text-align: right;\">0.0094</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">0.0286</td><td style = \"text-align: right;\">0.0453</td><td style = \"text-align: right;\">0.0277</td><td style = \"text-align: right;\">0.0174</td><td style = \"text-align: right;\">0.0384</td><td style = \"text-align: right;\">0.099</td><td style = \"text-align: right;\">0.1201</td><td style = \"text-align: right;\">0.1833</td><td style = \"text-align: right;\">0.2105</td><td style = \"text-align: right;\">0.3039</td><td style = \"text-align: right;\">0.2988</td><td style = \"text-align: right;\">0.425</td><td style = \"text-align: right;\">0.6343</td><td style = \"text-align: right;\">0.8198</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.9988</td><td style = \"text-align: right;\">0.9508</td><td style = \"text-align: right;\">0.9025</td><td style = \"text-align: right;\">0.7234</td><td style = \"text-align: right;\">0.5122</td><td style = \"text-align: right;\">0.2074</td><td style = \"text-align: right;\">0.3985</td><td style = \"text-align: right;\">0.589</td><td style = \"text-align: right;\">0.2872</td><td style = \"text-align: right;\">0.2043</td><td style = \"text-align: right;\">0.5782</td><td style = \"text-align: right;\">0.5389</td><td style = \"text-align: right;\">0.375</td><td style = \"text-align: right;\">0.3411</td><td style = \"text-align: right;\">0.5067</td><td style = \"text-align: right;\">0.558</td><td style = \"text-align: right;\">0.4778</td><td style = \"text-align: right;\">0.3299</td><td style = \"text-align: right;\">0.2198</td><td style = \"text-align: right;\">0.1407</td><td style = \"text-align: right;\">0.2856</td><td style = \"text-align: right;\">0.3807</td><td style = \"text-align: right;\">0.4158</td><td style = \"text-align: right;\">0.4054</td><td style = \"text-align: right;\">0.3296</td><td style = \"text-align: right;\">0.2707</td><td style = \"text-align: right;\">0.265</td><td style = \"text-align: right;\">0.0723</td><td style = \"text-align: right;\">0.1238</td><td style = \"text-align: right;\">0.1192</td><td style = \"text-align: right;\">0.1089</td><td style = \"text-align: right;\">0.0623</td><td style = \"text-align: right;\">0.0494</td><td style = \"text-align: right;\">0.0264</td><td style = \"text-align: right;\">0.0081</td><td style = \"text-align: right;\">0.0104</td><td style = \"text-align: right;\">0.0045</td><td style = \"text-align: right;\">0.0014</td><td style = \"text-align: right;\">0.0038</td><td style = \"text-align: right;\">0.0013</td><td style = \"text-align: right;\">0.0089</td><td style = \"text-align: right;\">0.0057</td><td style = \"text-align: right;\">0.0027</td><td style = \"text-align: right;\">0.0051</td><td style = \"text-align: right;\">0.0062</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">0.0317</td><td style = \"text-align: right;\">0.0956</td><td style = \"text-align: right;\">0.1321</td><td style = \"text-align: right;\">0.1408</td><td style = \"text-align: right;\">0.1674</td><td style = \"text-align: right;\">0.171</td><td style = \"text-align: right;\">0.0731</td><td style = \"text-align: right;\">0.1401</td><td style = \"text-align: right;\">0.2083</td><td style = \"text-align: right;\">0.3513</td><td style = \"text-align: right;\">0.1786</td><td style = \"text-align: right;\">0.0658</td><td style = \"text-align: right;\">0.0513</td><td style = \"text-align: right;\">0.3752</td><td style = \"text-align: right;\">0.5419</td><td style = \"text-align: right;\">0.544</td><td style = \"text-align: right;\">0.515</td><td style = \"text-align: right;\">0.4262</td><td style = \"text-align: right;\">0.2024</td><td style = \"text-align: right;\">0.4233</td><td style = \"text-align: right;\">0.7723</td><td style = \"text-align: right;\">0.9735</td><td style = \"text-align: right;\">0.939</td><td style = \"text-align: right;\">0.5559</td><td style = \"text-align: right;\">0.5268</td><td style = \"text-align: right;\">0.6826</td><td style = \"text-align: right;\">0.5713</td><td style = \"text-align: right;\">0.5429</td><td style = \"text-align: right;\">0.2177</td><td style = \"text-align: right;\">0.2149</td><td style = \"text-align: right;\">0.5811</td><td style = \"text-align: right;\">0.6323</td><td style = \"text-align: right;\">0.2965</td><td style = \"text-align: right;\">0.1873</td><td style = \"text-align: right;\">0.2969</td><td style = \"text-align: right;\">0.5163</td><td style = \"text-align: right;\">0.6153</td><td style = \"text-align: right;\">0.4283</td><td style = \"text-align: right;\">0.5479</td><td style = \"text-align: right;\">0.6133</td><td style = \"text-align: right;\">0.5017</td><td style = \"text-align: right;\">0.2377</td><td style = \"text-align: right;\">0.1957</td><td style = \"text-align: right;\">0.1749</td><td style = \"text-align: right;\">0.1304</td><td style = \"text-align: right;\">0.0597</td><td style = \"text-align: right;\">0.1124</td><td style = \"text-align: right;\">0.1047</td><td style = \"text-align: right;\">0.0507</td><td style = \"text-align: right;\">0.0159</td><td style = \"text-align: right;\">0.0195</td><td style = \"text-align: right;\">0.0201</td><td style = \"text-align: right;\">0.0248</td><td style = \"text-align: right;\">0.0131</td><td style = \"text-align: right;\">0.007</td><td style = \"text-align: right;\">0.0138</td><td style = \"text-align: right;\">0.0092</td><td style = \"text-align: right;\">0.0143</td><td style = \"text-align: right;\">0.0036</td><td style = \"text-align: right;\">0.0103</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">0.0519</td><td style = \"text-align: right;\">0.0548</td><td style = \"text-align: right;\">0.0842</td><td style = \"text-align: right;\">0.0319</td><td style = \"text-align: right;\">0.1158</td><td style = \"text-align: right;\">0.0922</td><td style = \"text-align: right;\">0.1027</td><td style = \"text-align: right;\">0.0613</td><td style = \"text-align: right;\">0.1465</td><td style = \"text-align: right;\">0.2838</td><td style = \"text-align: right;\">0.2802</td><td style = \"text-align: right;\">0.3086</td><td style = \"text-align: right;\">0.2657</td><td style = \"text-align: right;\">0.3801</td><td style = \"text-align: right;\">0.5626</td><td style = \"text-align: right;\">0.4376</td><td style = \"text-align: right;\">0.2617</td><td style = \"text-align: right;\">0.1199</td><td style = \"text-align: right;\">0.6676</td><td style = \"text-align: right;\">0.9402</td><td style = \"text-align: right;\">0.7832</td><td style = \"text-align: right;\">0.5352</td><td style = \"text-align: right;\">0.6809</td><td style = \"text-align: right;\">0.9174</td><td style = \"text-align: right;\">0.7613</td><td style = \"text-align: right;\">0.822</td><td style = \"text-align: right;\">0.8872</td><td style = \"text-align: right;\">0.6091</td><td style = \"text-align: right;\">0.2967</td><td style = \"text-align: right;\">0.1103</td><td style = \"text-align: right;\">0.1318</td><td style = \"text-align: right;\">0.0624</td><td style = \"text-align: right;\">0.099</td><td style = \"text-align: right;\">0.4006</td><td style = \"text-align: right;\">0.3666</td><td style = \"text-align: right;\">0.105</td><td style = \"text-align: right;\">0.1915</td><td style = \"text-align: right;\">0.393</td><td style = \"text-align: right;\">0.4288</td><td style = \"text-align: right;\">0.2546</td><td style = \"text-align: right;\">0.1151</td><td style = \"text-align: right;\">0.2196</td><td style = \"text-align: right;\">0.1879</td><td style = \"text-align: right;\">0.1437</td><td style = \"text-align: right;\">0.2146</td><td style = \"text-align: right;\">0.236</td><td style = \"text-align: right;\">0.1125</td><td style = \"text-align: right;\">0.0254</td><td style = \"text-align: right;\">0.0285</td><td style = \"text-align: right;\">0.0178</td><td style = \"text-align: right;\">0.0052</td><td style = \"text-align: right;\">0.0081</td><td style = \"text-align: right;\">0.012</td><td style = \"text-align: right;\">0.0045</td><td style = \"text-align: right;\">0.0121</td><td style = \"text-align: right;\">0.0097</td><td style = \"text-align: right;\">0.0085</td><td style = \"text-align: right;\">0.0047</td><td style = \"text-align: right;\">0.0048</td><td style = \"text-align: right;\">0.0053</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">0.0223</td><td style = \"text-align: right;\">0.0375</td><td style = \"text-align: right;\">0.0484</td><td style = \"text-align: right;\">0.0475</td><td style = \"text-align: right;\">0.0647</td><td style = \"text-align: right;\">0.0591</td><td style = \"text-align: right;\">0.0753</td><td style = \"text-align: right;\">0.0098</td><td style = \"text-align: right;\">0.0684</td><td style = \"text-align: right;\">0.1487</td><td style = \"text-align: right;\">0.1156</td><td style = \"text-align: right;\">0.1654</td><td style = \"text-align: right;\">0.3833</td><td style = \"text-align: right;\">0.3598</td><td style = \"text-align: right;\">0.1713</td><td style = \"text-align: right;\">0.1136</td><td style = \"text-align: right;\">0.0349</td><td style = \"text-align: right;\">0.3796</td><td style = \"text-align: right;\">0.7401</td><td style = \"text-align: right;\">0.9925</td><td style = \"text-align: right;\">0.9802</td><td style = \"text-align: right;\">0.889</td><td style = \"text-align: right;\">0.6712</td><td style = \"text-align: right;\">0.4286</td><td style = \"text-align: right;\">0.3374</td><td style = \"text-align: right;\">0.7366</td><td style = \"text-align: right;\">0.9611</td><td style = \"text-align: right;\">0.7353</td><td style = \"text-align: right;\">0.4856</td><td style = \"text-align: right;\">0.1594</td><td style = \"text-align: right;\">0.3007</td><td style = \"text-align: right;\">0.4096</td><td style = \"text-align: right;\">0.317</td><td style = \"text-align: right;\">0.3305</td><td style = \"text-align: right;\">0.3408</td><td style = \"text-align: right;\">0.2186</td><td style = \"text-align: right;\">0.2463</td><td style = \"text-align: right;\">0.2726</td><td style = \"text-align: right;\">0.168</td><td style = \"text-align: right;\">0.2792</td><td style = \"text-align: right;\">0.2558</td><td style = \"text-align: right;\">0.174</td><td style = \"text-align: right;\">0.2121</td><td style = \"text-align: right;\">0.1099</td><td style = \"text-align: right;\">0.0985</td><td style = \"text-align: right;\">0.1271</td><td style = \"text-align: right;\">0.1459</td><td style = \"text-align: right;\">0.1164</td><td style = \"text-align: right;\">0.0777</td><td style = \"text-align: right;\">0.0439</td><td style = \"text-align: right;\">0.0061</td><td style = \"text-align: right;\">0.0145</td><td style = \"text-align: right;\">0.0128</td><td style = \"text-align: right;\">0.0145</td><td style = \"text-align: right;\">0.0058</td><td style = \"text-align: right;\">0.0049</td><td style = \"text-align: right;\">0.0065</td><td style = \"text-align: right;\">0.0093</td><td style = \"text-align: right;\">0.0059</td><td style = \"text-align: right;\">0.0022</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">0.0164</td><td style = \"text-align: right;\">0.0173</td><td style = \"text-align: right;\">0.0347</td><td style = \"text-align: right;\">0.007</td><td style = \"text-align: right;\">0.0187</td><td style = \"text-align: right;\">0.0671</td><td style = \"text-align: right;\">0.1056</td><td style = \"text-align: right;\">0.0697</td><td style = \"text-align: right;\">0.0962</td><td style = \"text-align: right;\">0.0251</td><td style = \"text-align: right;\">0.0801</td><td style = \"text-align: right;\">0.1056</td><td style = \"text-align: right;\">0.1266</td><td style = \"text-align: right;\">0.089</td><td style = \"text-align: right;\">0.0198</td><td style = \"text-align: right;\">0.1133</td><td style = \"text-align: right;\">0.2826</td><td style = \"text-align: right;\">0.3234</td><td style = \"text-align: right;\">0.3238</td><td style = \"text-align: right;\">0.4333</td><td style = \"text-align: right;\">0.6068</td><td style = \"text-align: right;\">0.7652</td><td style = \"text-align: right;\">0.9203</td><td style = \"text-align: right;\">0.9719</td><td style = \"text-align: right;\">0.9207</td><td style = \"text-align: right;\">0.7545</td><td style = \"text-align: right;\">0.8289</td><td style = \"text-align: right;\">0.8907</td><td style = \"text-align: right;\">0.7309</td><td style = \"text-align: right;\">0.6896</td><td style = \"text-align: right;\">0.5829</td><td style = \"text-align: right;\">0.4935</td><td style = \"text-align: right;\">0.3101</td><td style = \"text-align: right;\">0.0306</td><td style = \"text-align: right;\">0.0244</td><td style = \"text-align: right;\">0.1108</td><td style = \"text-align: right;\">0.1594</td><td style = \"text-align: right;\">0.1371</td><td style = \"text-align: right;\">0.0696</td><td style = \"text-align: right;\">0.0452</td><td style = \"text-align: right;\">0.062</td><td style = \"text-align: right;\">0.1421</td><td style = \"text-align: right;\">0.1597</td><td style = \"text-align: right;\">0.1384</td><td style = \"text-align: right;\">0.0372</td><td style = \"text-align: right;\">0.0688</td><td style = \"text-align: right;\">0.0867</td><td style = \"text-align: right;\">0.0513</td><td style = \"text-align: right;\">0.0092</td><td style = \"text-align: right;\">0.0198</td><td style = \"text-align: right;\">0.0118</td><td style = \"text-align: right;\">0.009</td><td style = \"text-align: right;\">0.0223</td><td style = \"text-align: right;\">0.0179</td><td style = \"text-align: right;\">0.0084</td><td style = \"text-align: right;\">0.0068</td><td style = \"text-align: right;\">0.0032</td><td style = \"text-align: right;\">0.0035</td><td style = \"text-align: right;\">0.0056</td><td style = \"text-align: right;\">0.004</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">0.0039</td><td style = \"text-align: right;\">0.0063</td><td style = \"text-align: right;\">0.0152</td><td style = \"text-align: right;\">0.0336</td><td style = \"text-align: right;\">0.031</td><td style = \"text-align: right;\">0.0284</td><td style = \"text-align: right;\">0.0396</td><td style = \"text-align: right;\">0.0272</td><td style = \"text-align: right;\">0.0323</td><td style = \"text-align: right;\">0.0452</td><td style = \"text-align: right;\">0.0492</td><td style = \"text-align: right;\">0.0996</td><td style = \"text-align: right;\">0.1424</td><td style = \"text-align: right;\">0.1194</td><td style = \"text-align: right;\">0.0628</td><td style = \"text-align: right;\">0.0907</td><td style = \"text-align: right;\">0.1177</td><td style = \"text-align: right;\">0.1429</td><td style = \"text-align: right;\">0.1223</td><td style = \"text-align: right;\">0.1104</td><td style = \"text-align: right;\">0.1847</td><td style = \"text-align: right;\">0.3715</td><td style = \"text-align: right;\">0.4382</td><td style = \"text-align: right;\">0.5707</td><td style = \"text-align: right;\">0.6654</td><td style = \"text-align: right;\">0.7476</td><td style = \"text-align: right;\">0.7654</td><td style = \"text-align: right;\">0.8555</td><td style = \"text-align: right;\">0.972</td><td style = \"text-align: right;\">0.9221</td><td style = \"text-align: right;\">0.7502</td><td style = \"text-align: right;\">0.7209</td><td style = \"text-align: right;\">0.7757</td><td style = \"text-align: right;\">0.6055</td><td style = \"text-align: right;\">0.5021</td><td style = \"text-align: right;\">0.4499</td><td style = \"text-align: right;\">0.3947</td><td style = \"text-align: right;\">0.4281</td><td style = \"text-align: right;\">0.4427</td><td style = \"text-align: right;\">0.3749</td><td style = \"text-align: right;\">0.1972</td><td style = \"text-align: right;\">0.0511</td><td style = \"text-align: right;\">0.0793</td><td style = \"text-align: right;\">0.1269</td><td style = \"text-align: right;\">0.1533</td><td style = \"text-align: right;\">0.069</td><td style = \"text-align: right;\">0.0402</td><td style = \"text-align: right;\">0.0534</td><td style = \"text-align: right;\">0.0228</td><td style = \"text-align: right;\">0.0073</td><td style = \"text-align: right;\">0.0062</td><td style = \"text-align: right;\">0.0062</td><td style = \"text-align: right;\">0.012</td><td style = \"text-align: right;\">0.0052</td><td style = \"text-align: right;\">0.0056</td><td style = \"text-align: right;\">0.0093</td><td style = \"text-align: right;\">0.0042</td><td style = \"text-align: right;\">0.0003</td><td style = \"text-align: right;\">0.0053</td><td style = \"text-align: right;\">0.0036</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">0.0123</td><td style = \"text-align: right;\">0.0309</td><td style = \"text-align: right;\">0.0169</td><td style = \"text-align: right;\">0.0313</td><td style = \"text-align: right;\">0.0358</td><td style = \"text-align: right;\">0.0102</td><td style = \"text-align: right;\">0.0182</td><td style = \"text-align: right;\">0.0579</td><td style = \"text-align: right;\">0.1122</td><td style = \"text-align: right;\">0.0835</td><td style = \"text-align: right;\">0.0548</td><td style = \"text-align: right;\">0.0847</td><td style = \"text-align: right;\">0.2026</td><td style = \"text-align: right;\">0.2557</td><td style = \"text-align: right;\">0.187</td><td style = \"text-align: right;\">0.2032</td><td style = \"text-align: right;\">0.1463</td><td style = \"text-align: right;\">0.2849</td><td style = \"text-align: right;\">0.5824</td><td style = \"text-align: right;\">0.7728</td><td style = \"text-align: right;\">0.7852</td><td style = \"text-align: right;\">0.8515</td><td style = \"text-align: right;\">0.5312</td><td style = \"text-align: right;\">0.3653</td><td style = \"text-align: right;\">0.5973</td><td style = \"text-align: right;\">0.8275</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.8673</td><td style = \"text-align: right;\">0.6301</td><td style = \"text-align: right;\">0.4591</td><td style = \"text-align: right;\">0.394</td><td style = \"text-align: right;\">0.2576</td><td style = \"text-align: right;\">0.2817</td><td style = \"text-align: right;\">0.2641</td><td style = \"text-align: right;\">0.2757</td><td style = \"text-align: right;\">0.2698</td><td style = \"text-align: right;\">0.3994</td><td style = \"text-align: right;\">0.4576</td><td style = \"text-align: right;\">0.394</td><td style = \"text-align: right;\">0.2522</td><td style = \"text-align: right;\">0.1782</td><td style = \"text-align: right;\">0.1354</td><td style = \"text-align: right;\">0.0516</td><td style = \"text-align: right;\">0.0337</td><td style = \"text-align: right;\">0.0894</td><td style = \"text-align: right;\">0.0861</td><td style = \"text-align: right;\">0.0872</td><td style = \"text-align: right;\">0.0445</td><td style = \"text-align: right;\">0.0134</td><td style = \"text-align: right;\">0.0217</td><td style = \"text-align: right;\">0.0188</td><td style = \"text-align: right;\">0.0133</td><td style = \"text-align: right;\">0.0265</td><td style = \"text-align: right;\">0.0224</td><td style = \"text-align: right;\">0.0074</td><td style = \"text-align: right;\">0.0118</td><td style = \"text-align: right;\">0.0026</td><td style = \"text-align: right;\">0.0092</td><td style = \"text-align: right;\">0.0009</td><td style = \"text-align: right;\">0.0044</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">0.0079</td><td style = \"text-align: right;\">0.0086</td><td style = \"text-align: right;\">0.0055</td><td style = \"text-align: right;\">0.025</td><td style = \"text-align: right;\">0.0344</td><td style = \"text-align: right;\">0.0546</td><td style = \"text-align: right;\">0.0528</td><td style = \"text-align: right;\">0.0958</td><td style = \"text-align: right;\">0.1009</td><td style = \"text-align: right;\">0.124</td><td style = \"text-align: right;\">0.1097</td><td style = \"text-align: right;\">0.1215</td><td style = \"text-align: right;\">0.1874</td><td style = \"text-align: right;\">0.3383</td><td style = \"text-align: right;\">0.3227</td><td style = \"text-align: right;\">0.2723</td><td style = \"text-align: right;\">0.3943</td><td style = \"text-align: right;\">0.6432</td><td style = \"text-align: right;\">0.7271</td><td style = \"text-align: right;\">0.8673</td><td style = \"text-align: right;\">0.9674</td><td style = \"text-align: right;\">0.9847</td><td style = \"text-align: right;\">0.948</td><td style = \"text-align: right;\">0.8036</td><td style = \"text-align: right;\">0.6833</td><td style = \"text-align: right;\">0.5136</td><td style = \"text-align: right;\">0.309</td><td style = \"text-align: right;\">0.0832</td><td style = \"text-align: right;\">0.4019</td><td style = \"text-align: right;\">0.2344</td><td style = \"text-align: right;\">0.1905</td><td style = \"text-align: right;\">0.1235</td><td style = \"text-align: right;\">0.1717</td><td style = \"text-align: right;\">0.2351</td><td style = \"text-align: right;\">0.2489</td><td style = \"text-align: right;\">0.3649</td><td style = \"text-align: right;\">0.3382</td><td style = \"text-align: right;\">0.1589</td><td style = \"text-align: right;\">0.0989</td><td style = \"text-align: right;\">0.1089</td><td style = \"text-align: right;\">0.1043</td><td style = \"text-align: right;\">0.0839</td><td style = \"text-align: right;\">0.1391</td><td style = \"text-align: right;\">0.0819</td><td style = \"text-align: right;\">0.0678</td><td style = \"text-align: right;\">0.0663</td><td style = \"text-align: right;\">0.1202</td><td style = \"text-align: right;\">0.0692</td><td style = \"text-align: right;\">0.0152</td><td style = \"text-align: right;\">0.0266</td><td style = \"text-align: right;\">0.0174</td><td style = \"text-align: right;\">0.0176</td><td style = \"text-align: right;\">0.0127</td><td style = \"text-align: right;\">0.0088</td><td style = \"text-align: right;\">0.0098</td><td style = \"text-align: right;\">0.0019</td><td style = \"text-align: right;\">0.0059</td><td style = \"text-align: right;\">0.0058</td><td style = \"text-align: right;\">0.0059</td><td style = \"text-align: right;\">0.0032</td><td style = \"text-align: left;\">R</td><td style = \"text-align: right;\">false</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">197</td><td style = \"text-align: right;\">0.005</td><td style = \"text-align: right;\">0.0017</td><td style = \"text-align: right;\">0.027</td><td style = \"text-align: right;\">0.045</td><td style = \"text-align: right;\">0.0958</td><td style = \"text-align: right;\">0.083</td><td style = \"text-align: right;\">0.0879</td><td style = \"text-align: right;\">0.122</td><td style = \"text-align: right;\">0.1977</td><td style = \"text-align: right;\">0.2282</td><td style = \"text-align: right;\">0.2521</td><td style = \"text-align: right;\">0.3484</td><td style = \"text-align: right;\">0.3309</td><td style = \"text-align: right;\">0.2614</td><td style = \"text-align: right;\">0.1782</td><td style = \"text-align: right;\">0.2055</td><td style = \"text-align: right;\">0.2298</td><td style = \"text-align: right;\">0.3545</td><td style = \"text-align: right;\">0.6218</td><td style = \"text-align: right;\">0.7265</td><td style = \"text-align: right;\">0.8346</td><td style = \"text-align: right;\">0.8268</td><td style = \"text-align: right;\">0.8366</td><td style = \"text-align: right;\">0.9408</td><td style = \"text-align: right;\">0.951</td><td style = \"text-align: right;\">0.9801</td><td style = \"text-align: right;\">0.9974</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.9036</td><td style = \"text-align: right;\">0.6409</td><td style = \"text-align: right;\">0.3857</td><td style = \"text-align: right;\">0.2908</td><td style = \"text-align: right;\">0.204</td><td style = \"text-align: right;\">0.1653</td><td style = \"text-align: right;\">0.1769</td><td style = \"text-align: right;\">0.114</td><td style = \"text-align: right;\">0.074</td><td style = \"text-align: right;\">0.0941</td><td style = \"text-align: right;\">0.0621</td><td style = \"text-align: right;\">0.0426</td><td style = \"text-align: right;\">0.0572</td><td style = \"text-align: right;\">0.1068</td><td style = \"text-align: right;\">0.1909</td><td style = \"text-align: right;\">0.2229</td><td style = \"text-align: right;\">0.2203</td><td style = \"text-align: right;\">0.2265</td><td style = \"text-align: right;\">0.1766</td><td style = \"text-align: right;\">0.1097</td><td style = \"text-align: right;\">0.0558</td><td style = \"text-align: right;\">0.0142</td><td style = \"text-align: right;\">0.0281</td><td style = \"text-align: right;\">0.0165</td><td style = \"text-align: right;\">0.0056</td><td style = \"text-align: right;\">0.001</td><td style = \"text-align: right;\">0.0027</td><td style = \"text-align: right;\">0.0062</td><td style = \"text-align: right;\">0.0024</td><td style = \"text-align: right;\">0.0063</td><td style = \"text-align: right;\">0.0017</td><td style = \"text-align: right;\">0.0028</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">198</td><td style = \"text-align: right;\">0.0366</td><td style = \"text-align: right;\">0.0421</td><td style = \"text-align: right;\">0.0504</td><td style = \"text-align: right;\">0.025</td><td style = \"text-align: right;\">0.0596</td><td style = \"text-align: right;\">0.0252</td><td style = \"text-align: right;\">0.0958</td><td style = \"text-align: right;\">0.0991</td><td style = \"text-align: right;\">0.1419</td><td style = \"text-align: right;\">0.1847</td><td style = \"text-align: right;\">0.2222</td><td style = \"text-align: right;\">0.2648</td><td style = \"text-align: right;\">0.2508</td><td style = \"text-align: right;\">0.2291</td><td style = \"text-align: right;\">0.1555</td><td style = \"text-align: right;\">0.1863</td><td style = \"text-align: right;\">0.2387</td><td style = \"text-align: right;\">0.3345</td><td style = \"text-align: right;\">0.5233</td><td style = \"text-align: right;\">0.6684</td><td style = \"text-align: right;\">0.7766</td><td style = \"text-align: right;\">0.7928</td><td style = \"text-align: right;\">0.794</td><td style = \"text-align: right;\">0.9129</td><td style = \"text-align: right;\">0.9498</td><td style = \"text-align: right;\">0.9835</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.9471</td><td style = \"text-align: right;\">0.8237</td><td style = \"text-align: right;\">0.6252</td><td style = \"text-align: right;\">0.4181</td><td style = \"text-align: right;\">0.3209</td><td style = \"text-align: right;\">0.2658</td><td style = \"text-align: right;\">0.2196</td><td style = \"text-align: right;\">0.1588</td><td style = \"text-align: right;\">0.0561</td><td style = \"text-align: right;\">0.0948</td><td style = \"text-align: right;\">0.17</td><td style = \"text-align: right;\">0.1215</td><td style = \"text-align: right;\">0.1282</td><td style = \"text-align: right;\">0.0386</td><td style = \"text-align: right;\">0.1329</td><td style = \"text-align: right;\">0.2331</td><td style = \"text-align: right;\">0.2468</td><td style = \"text-align: right;\">0.196</td><td style = \"text-align: right;\">0.1985</td><td style = \"text-align: right;\">0.157</td><td style = \"text-align: right;\">0.0921</td><td style = \"text-align: right;\">0.0549</td><td style = \"text-align: right;\">0.0194</td><td style = \"text-align: right;\">0.0166</td><td style = \"text-align: right;\">0.0132</td><td style = \"text-align: right;\">0.0027</td><td style = \"text-align: right;\">0.0022</td><td style = \"text-align: right;\">0.0059</td><td style = \"text-align: right;\">0.0016</td><td style = \"text-align: right;\">0.0025</td><td style = \"text-align: right;\">0.0017</td><td style = \"text-align: right;\">0.0027</td><td style = \"text-align: right;\">0.0027</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">199</td><td style = \"text-align: right;\">0.0238</td><td style = \"text-align: right;\">0.0318</td><td style = \"text-align: right;\">0.0422</td><td style = \"text-align: right;\">0.0399</td><td style = \"text-align: right;\">0.0788</td><td style = \"text-align: right;\">0.0766</td><td style = \"text-align: right;\">0.0881</td><td style = \"text-align: right;\">0.1143</td><td style = \"text-align: right;\">0.1594</td><td style = \"text-align: right;\">0.2048</td><td style = \"text-align: right;\">0.2652</td><td style = \"text-align: right;\">0.31</td><td style = \"text-align: right;\">0.2381</td><td style = \"text-align: right;\">0.1918</td><td style = \"text-align: right;\">0.143</td><td style = \"text-align: right;\">0.1735</td><td style = \"text-align: right;\">0.1781</td><td style = \"text-align: right;\">0.2852</td><td style = \"text-align: right;\">0.5036</td><td style = \"text-align: right;\">0.6166</td><td style = \"text-align: right;\">0.7616</td><td style = \"text-align: right;\">0.8125</td><td style = \"text-align: right;\">0.7793</td><td style = \"text-align: right;\">0.8788</td><td style = \"text-align: right;\">0.8813</td><td style = \"text-align: right;\">0.947</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.9739</td><td style = \"text-align: right;\">0.8446</td><td style = \"text-align: right;\">0.6151</td><td style = \"text-align: right;\">0.4302</td><td style = \"text-align: right;\">0.3165</td><td style = \"text-align: right;\">0.2869</td><td style = \"text-align: right;\">0.2017</td><td style = \"text-align: right;\">0.1206</td><td style = \"text-align: right;\">0.0271</td><td style = \"text-align: right;\">0.058</td><td style = \"text-align: right;\">0.1262</td><td style = \"text-align: right;\">0.1072</td><td style = \"text-align: right;\">0.1082</td><td style = \"text-align: right;\">0.036</td><td style = \"text-align: right;\">0.1197</td><td style = \"text-align: right;\">0.2061</td><td style = \"text-align: right;\">0.2054</td><td style = \"text-align: right;\">0.1878</td><td style = \"text-align: right;\">0.2047</td><td style = \"text-align: right;\">0.1716</td><td style = \"text-align: right;\">0.1069</td><td style = \"text-align: right;\">0.0477</td><td style = \"text-align: right;\">0.017</td><td style = \"text-align: right;\">0.0186</td><td style = \"text-align: right;\">0.0096</td><td style = \"text-align: right;\">0.0071</td><td style = \"text-align: right;\">0.0084</td><td style = \"text-align: right;\">0.0038</td><td style = \"text-align: right;\">0.0026</td><td style = \"text-align: right;\">0.0028</td><td style = \"text-align: right;\">0.0013</td><td style = \"text-align: right;\">0.0035</td><td style = \"text-align: right;\">0.006</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">200</td><td style = \"text-align: right;\">0.0116</td><td style = \"text-align: right;\">0.0744</td><td style = \"text-align: right;\">0.0367</td><td style = \"text-align: right;\">0.0225</td><td style = \"text-align: right;\">0.0076</td><td style = \"text-align: right;\">0.0545</td><td style = \"text-align: right;\">0.111</td><td style = \"text-align: right;\">0.1069</td><td style = \"text-align: right;\">0.1708</td><td style = \"text-align: right;\">0.2271</td><td style = \"text-align: right;\">0.3171</td><td style = \"text-align: right;\">0.2882</td><td style = \"text-align: right;\">0.2657</td><td style = \"text-align: right;\">0.2307</td><td style = \"text-align: right;\">0.1889</td><td style = \"text-align: right;\">0.1791</td><td style = \"text-align: right;\">0.2298</td><td style = \"text-align: right;\">0.3715</td><td style = \"text-align: right;\">0.6223</td><td style = \"text-align: right;\">0.726</td><td style = \"text-align: right;\">0.7934</td><td style = \"text-align: right;\">0.8045</td><td style = \"text-align: right;\">0.8067</td><td style = \"text-align: right;\">0.9173</td><td style = \"text-align: right;\">0.9327</td><td style = \"text-align: right;\">0.9562</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.9818</td><td style = \"text-align: right;\">0.8684</td><td style = \"text-align: right;\">0.6381</td><td style = \"text-align: right;\">0.3997</td><td style = \"text-align: right;\">0.3242</td><td style = \"text-align: right;\">0.2835</td><td style = \"text-align: right;\">0.2413</td><td style = \"text-align: right;\">0.2321</td><td style = \"text-align: right;\">0.126</td><td style = \"text-align: right;\">0.0693</td><td style = \"text-align: right;\">0.0701</td><td style = \"text-align: right;\">0.1439</td><td style = \"text-align: right;\">0.1475</td><td style = \"text-align: right;\">0.0438</td><td style = \"text-align: right;\">0.0469</td><td style = \"text-align: right;\">0.1476</td><td style = \"text-align: right;\">0.1742</td><td style = \"text-align: right;\">0.1555</td><td style = \"text-align: right;\">0.1651</td><td style = \"text-align: right;\">0.1181</td><td style = \"text-align: right;\">0.072</td><td style = \"text-align: right;\">0.0321</td><td style = \"text-align: right;\">0.0056</td><td style = \"text-align: right;\">0.0202</td><td style = \"text-align: right;\">0.0141</td><td style = \"text-align: right;\">0.0103</td><td style = \"text-align: right;\">0.01</td><td style = \"text-align: right;\">0.0034</td><td style = \"text-align: right;\">0.0026</td><td style = \"text-align: right;\">0.0037</td><td style = \"text-align: right;\">0.0044</td><td style = \"text-align: right;\">0.0057</td><td style = \"text-align: right;\">0.0035</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">201</td><td style = \"text-align: right;\">0.0131</td><td style = \"text-align: right;\">0.0387</td><td style = \"text-align: right;\">0.0329</td><td style = \"text-align: right;\">0.0078</td><td style = \"text-align: right;\">0.0721</td><td style = \"text-align: right;\">0.1341</td><td style = \"text-align: right;\">0.1626</td><td style = \"text-align: right;\">0.1902</td><td style = \"text-align: right;\">0.261</td><td style = \"text-align: right;\">0.3193</td><td style = \"text-align: right;\">0.3468</td><td style = \"text-align: right;\">0.3738</td><td style = \"text-align: right;\">0.3055</td><td style = \"text-align: right;\">0.1926</td><td style = \"text-align: right;\">0.1385</td><td style = \"text-align: right;\">0.2122</td><td style = \"text-align: right;\">0.2758</td><td style = \"text-align: right;\">0.4576</td><td style = \"text-align: right;\">0.6487</td><td style = \"text-align: right;\">0.7154</td><td style = \"text-align: right;\">0.801</td><td style = \"text-align: right;\">0.7924</td><td style = \"text-align: right;\">0.8793</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.9865</td><td style = \"text-align: right;\">0.9474</td><td style = \"text-align: right;\">0.9474</td><td style = \"text-align: right;\">0.9315</td><td style = \"text-align: right;\">0.8326</td><td style = \"text-align: right;\">0.6213</td><td style = \"text-align: right;\">0.3772</td><td style = \"text-align: right;\">0.2822</td><td style = \"text-align: right;\">0.2042</td><td style = \"text-align: right;\">0.219</td><td style = \"text-align: right;\">0.2223</td><td style = \"text-align: right;\">0.1327</td><td style = \"text-align: right;\">0.0521</td><td style = \"text-align: right;\">0.0618</td><td style = \"text-align: right;\">0.1416</td><td style = \"text-align: right;\">0.146</td><td style = \"text-align: right;\">0.0846</td><td style = \"text-align: right;\">0.1055</td><td style = \"text-align: right;\">0.1639</td><td style = \"text-align: right;\">0.1916</td><td style = \"text-align: right;\">0.2085</td><td style = \"text-align: right;\">0.2335</td><td style = \"text-align: right;\">0.1964</td><td style = \"text-align: right;\">0.13</td><td style = \"text-align: right;\">0.0633</td><td style = \"text-align: right;\">0.0183</td><td style = \"text-align: right;\">0.0137</td><td style = \"text-align: right;\">0.015</td><td style = \"text-align: right;\">0.0076</td><td style = \"text-align: right;\">0.0032</td><td style = \"text-align: right;\">0.0037</td><td style = \"text-align: right;\">0.0071</td><td style = \"text-align: right;\">0.004</td><td style = \"text-align: right;\">0.0009</td><td style = \"text-align: right;\">0.0015</td><td style = \"text-align: right;\">0.0085</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">202</td><td style = \"text-align: right;\">0.0335</td><td style = \"text-align: right;\">0.0258</td><td style = \"text-align: right;\">0.0398</td><td style = \"text-align: right;\">0.057</td><td style = \"text-align: right;\">0.0529</td><td style = \"text-align: right;\">0.1091</td><td style = \"text-align: right;\">0.1709</td><td style = \"text-align: right;\">0.1684</td><td style = \"text-align: right;\">0.1865</td><td style = \"text-align: right;\">0.266</td><td style = \"text-align: right;\">0.3188</td><td style = \"text-align: right;\">0.3553</td><td style = \"text-align: right;\">0.3116</td><td style = \"text-align: right;\">0.1965</td><td style = \"text-align: right;\">0.178</td><td style = \"text-align: right;\">0.2794</td><td style = \"text-align: right;\">0.287</td><td style = \"text-align: right;\">0.3969</td><td style = \"text-align: right;\">0.5599</td><td style = \"text-align: right;\">0.6936</td><td style = \"text-align: right;\">0.7969</td><td style = \"text-align: right;\">0.7452</td><td style = \"text-align: right;\">0.8203</td><td style = \"text-align: right;\">0.9261</td><td style = \"text-align: right;\">0.881</td><td style = \"text-align: right;\">0.8814</td><td style = \"text-align: right;\">0.9301</td><td style = \"text-align: right;\">0.9955</td><td style = \"text-align: right;\">0.8576</td><td style = \"text-align: right;\">0.6069</td><td style = \"text-align: right;\">0.3934</td><td style = \"text-align: right;\">0.2464</td><td style = \"text-align: right;\">0.1645</td><td style = \"text-align: right;\">0.114</td><td style = \"text-align: right;\">0.0956</td><td style = \"text-align: right;\">0.008</td><td style = \"text-align: right;\">0.0702</td><td style = \"text-align: right;\">0.0936</td><td style = \"text-align: right;\">0.0894</td><td style = \"text-align: right;\">0.1127</td><td style = \"text-align: right;\">0.0873</td><td style = \"text-align: right;\">0.102</td><td style = \"text-align: right;\">0.1964</td><td style = \"text-align: right;\">0.2256</td><td style = \"text-align: right;\">0.1814</td><td style = \"text-align: right;\">0.2012</td><td style = \"text-align: right;\">0.1688</td><td style = \"text-align: right;\">0.1037</td><td style = \"text-align: right;\">0.0501</td><td style = \"text-align: right;\">0.0136</td><td style = \"text-align: right;\">0.013</td><td style = \"text-align: right;\">0.012</td><td style = \"text-align: right;\">0.0039</td><td style = \"text-align: right;\">0.0053</td><td style = \"text-align: right;\">0.0062</td><td style = \"text-align: right;\">0.0046</td><td style = \"text-align: right;\">0.0045</td><td style = \"text-align: right;\">0.0022</td><td style = \"text-align: right;\">0.0005</td><td style = \"text-align: right;\">0.0031</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">203</td><td style = \"text-align: right;\">0.0272</td><td style = \"text-align: right;\">0.0378</td><td style = \"text-align: right;\">0.0488</td><td style = \"text-align: right;\">0.0848</td><td style = \"text-align: right;\">0.1127</td><td style = \"text-align: right;\">0.1103</td><td style = \"text-align: right;\">0.1349</td><td style = \"text-align: right;\">0.2337</td><td style = \"text-align: right;\">0.3113</td><td style = \"text-align: right;\">0.3997</td><td style = \"text-align: right;\">0.3941</td><td style = \"text-align: right;\">0.3309</td><td style = \"text-align: right;\">0.2926</td><td style = \"text-align: right;\">0.176</td><td style = \"text-align: right;\">0.1739</td><td style = \"text-align: right;\">0.2043</td><td style = \"text-align: right;\">0.2088</td><td style = \"text-align: right;\">0.2678</td><td style = \"text-align: right;\">0.2434</td><td style = \"text-align: right;\">0.1839</td><td style = \"text-align: right;\">0.2802</td><td style = \"text-align: right;\">0.6172</td><td style = \"text-align: right;\">0.8015</td><td style = \"text-align: right;\">0.8313</td><td style = \"text-align: right;\">0.844</td><td style = \"text-align: right;\">0.8494</td><td style = \"text-align: right;\">0.9168</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.7896</td><td style = \"text-align: right;\">0.5371</td><td style = \"text-align: right;\">0.6472</td><td style = \"text-align: right;\">0.6505</td><td style = \"text-align: right;\">0.4959</td><td style = \"text-align: right;\">0.2175</td><td style = \"text-align: right;\">0.099</td><td style = \"text-align: right;\">0.0434</td><td style = \"text-align: right;\">0.1708</td><td style = \"text-align: right;\">0.1979</td><td style = \"text-align: right;\">0.188</td><td style = \"text-align: right;\">0.1108</td><td style = \"text-align: right;\">0.1702</td><td style = \"text-align: right;\">0.0585</td><td style = \"text-align: right;\">0.0638</td><td style = \"text-align: right;\">0.1391</td><td style = \"text-align: right;\">0.0638</td><td style = \"text-align: right;\">0.0581</td><td style = \"text-align: right;\">0.0641</td><td style = \"text-align: right;\">0.1044</td><td style = \"text-align: right;\">0.0732</td><td style = \"text-align: right;\">0.0275</td><td style = \"text-align: right;\">0.0146</td><td style = \"text-align: right;\">0.0091</td><td style = \"text-align: right;\">0.0045</td><td style = \"text-align: right;\">0.0043</td><td style = \"text-align: right;\">0.0043</td><td style = \"text-align: right;\">0.0098</td><td style = \"text-align: right;\">0.0054</td><td style = \"text-align: right;\">0.0051</td><td style = \"text-align: right;\">0.0065</td><td style = \"text-align: right;\">0.0103</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">204</td><td style = \"text-align: right;\">0.0187</td><td style = \"text-align: right;\">0.0346</td><td style = \"text-align: right;\">0.0168</td><td style = \"text-align: right;\">0.0177</td><td style = \"text-align: right;\">0.0393</td><td style = \"text-align: right;\">0.163</td><td style = \"text-align: right;\">0.2028</td><td style = \"text-align: right;\">0.1694</td><td style = \"text-align: right;\">0.2328</td><td style = \"text-align: right;\">0.2684</td><td style = \"text-align: right;\">0.3108</td><td style = \"text-align: right;\">0.2933</td><td style = \"text-align: right;\">0.2275</td><td style = \"text-align: right;\">0.0994</td><td style = \"text-align: right;\">0.1801</td><td style = \"text-align: right;\">0.22</td><td style = \"text-align: right;\">0.2732</td><td style = \"text-align: right;\">0.2862</td><td style = \"text-align: right;\">0.2034</td><td style = \"text-align: right;\">0.174</td><td style = \"text-align: right;\">0.413</td><td style = \"text-align: right;\">0.6879</td><td style = \"text-align: right;\">0.812</td><td style = \"text-align: right;\">0.8453</td><td style = \"text-align: right;\">0.8919</td><td style = \"text-align: right;\">0.93</td><td style = \"text-align: right;\">0.9987</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.8104</td><td style = \"text-align: right;\">0.6199</td><td style = \"text-align: right;\">0.6041</td><td style = \"text-align: right;\">0.5547</td><td style = \"text-align: right;\">0.416</td><td style = \"text-align: right;\">0.1472</td><td style = \"text-align: right;\">0.0849</td><td style = \"text-align: right;\">0.0608</td><td style = \"text-align: right;\">0.0969</td><td style = \"text-align: right;\">0.1411</td><td style = \"text-align: right;\">0.1676</td><td style = \"text-align: right;\">0.12</td><td style = \"text-align: right;\">0.1201</td><td style = \"text-align: right;\">0.1036</td><td style = \"text-align: right;\">0.1977</td><td style = \"text-align: right;\">0.1339</td><td style = \"text-align: right;\">0.0902</td><td style = \"text-align: right;\">0.1085</td><td style = \"text-align: right;\">0.1521</td><td style = \"text-align: right;\">0.1363</td><td style = \"text-align: right;\">0.0858</td><td style = \"text-align: right;\">0.029</td><td style = \"text-align: right;\">0.0203</td><td style = \"text-align: right;\">0.0116</td><td style = \"text-align: right;\">0.0098</td><td style = \"text-align: right;\">0.0199</td><td style = \"text-align: right;\">0.0033</td><td style = \"text-align: right;\">0.0101</td><td style = \"text-align: right;\">0.0065</td><td style = \"text-align: right;\">0.0115</td><td style = \"text-align: right;\">0.0193</td><td style = \"text-align: right;\">0.0157</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">205</td><td style = \"text-align: right;\">0.0323</td><td style = \"text-align: right;\">0.0101</td><td style = \"text-align: right;\">0.0298</td><td style = \"text-align: right;\">0.0564</td><td style = \"text-align: right;\">0.076</td><td style = \"text-align: right;\">0.0958</td><td style = \"text-align: right;\">0.099</td><td style = \"text-align: right;\">0.1018</td><td style = \"text-align: right;\">0.103</td><td style = \"text-align: right;\">0.2154</td><td style = \"text-align: right;\">0.3085</td><td style = \"text-align: right;\">0.3425</td><td style = \"text-align: right;\">0.299</td><td style = \"text-align: right;\">0.1402</td><td style = \"text-align: right;\">0.1235</td><td style = \"text-align: right;\">0.1534</td><td style = \"text-align: right;\">0.1901</td><td style = \"text-align: right;\">0.2429</td><td style = \"text-align: right;\">0.212</td><td style = \"text-align: right;\">0.2395</td><td style = \"text-align: right;\">0.3272</td><td style = \"text-align: right;\">0.5949</td><td style = \"text-align: right;\">0.8302</td><td style = \"text-align: right;\">0.9045</td><td style = \"text-align: right;\">0.9888</td><td style = \"text-align: right;\">0.9912</td><td style = \"text-align: right;\">0.9448</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.9092</td><td style = \"text-align: right;\">0.7412</td><td style = \"text-align: right;\">0.7691</td><td style = \"text-align: right;\">0.7117</td><td style = \"text-align: right;\">0.5304</td><td style = \"text-align: right;\">0.2131</td><td style = \"text-align: right;\">0.0928</td><td style = \"text-align: right;\">0.1297</td><td style = \"text-align: right;\">0.1159</td><td style = \"text-align: right;\">0.1226</td><td style = \"text-align: right;\">0.1768</td><td style = \"text-align: right;\">0.0345</td><td style = \"text-align: right;\">0.1562</td><td style = \"text-align: right;\">0.0824</td><td style = \"text-align: right;\">0.1149</td><td style = \"text-align: right;\">0.1694</td><td style = \"text-align: right;\">0.0954</td><td style = \"text-align: right;\">0.008</td><td style = \"text-align: right;\">0.079</td><td style = \"text-align: right;\">0.1255</td><td style = \"text-align: right;\">0.0647</td><td style = \"text-align: right;\">0.0179</td><td style = \"text-align: right;\">0.0051</td><td style = \"text-align: right;\">0.0061</td><td style = \"text-align: right;\">0.0093</td><td style = \"text-align: right;\">0.0135</td><td style = \"text-align: right;\">0.0063</td><td style = \"text-align: right;\">0.0063</td><td style = \"text-align: right;\">0.0034</td><td style = \"text-align: right;\">0.0032</td><td style = \"text-align: right;\">0.0062</td><td style = \"text-align: right;\">0.0067</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">206</td><td style = \"text-align: right;\">0.0522</td><td style = \"text-align: right;\">0.0437</td><td style = \"text-align: right;\">0.018</td><td style = \"text-align: right;\">0.0292</td><td style = \"text-align: right;\">0.0351</td><td style = \"text-align: right;\">0.1171</td><td style = \"text-align: right;\">0.1257</td><td style = \"text-align: right;\">0.1178</td><td style = \"text-align: right;\">0.1258</td><td style = \"text-align: right;\">0.2529</td><td style = \"text-align: right;\">0.2716</td><td style = \"text-align: right;\">0.2374</td><td style = \"text-align: right;\">0.1878</td><td style = \"text-align: right;\">0.0983</td><td style = \"text-align: right;\">0.0683</td><td style = \"text-align: right;\">0.1503</td><td style = \"text-align: right;\">0.1723</td><td style = \"text-align: right;\">0.2339</td><td style = \"text-align: right;\">0.1962</td><td style = \"text-align: right;\">0.1395</td><td style = \"text-align: right;\">0.3164</td><td style = \"text-align: right;\">0.5888</td><td style = \"text-align: right;\">0.7631</td><td style = \"text-align: right;\">0.8473</td><td style = \"text-align: right;\">0.9424</td><td style = \"text-align: right;\">0.9986</td><td style = \"text-align: right;\">0.9699</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.863</td><td style = \"text-align: right;\">0.6979</td><td style = \"text-align: right;\">0.7717</td><td style = \"text-align: right;\">0.7305</td><td style = \"text-align: right;\">0.5197</td><td style = \"text-align: right;\">0.1786</td><td style = \"text-align: right;\">0.1098</td><td style = \"text-align: right;\">0.1446</td><td style = \"text-align: right;\">0.1066</td><td style = \"text-align: right;\">0.144</td><td style = \"text-align: right;\">0.1929</td><td style = \"text-align: right;\">0.0325</td><td style = \"text-align: right;\">0.149</td><td style = \"text-align: right;\">0.0328</td><td style = \"text-align: right;\">0.0537</td><td style = \"text-align: right;\">0.1309</td><td style = \"text-align: right;\">0.091</td><td style = \"text-align: right;\">0.0757</td><td style = \"text-align: right;\">0.1059</td><td style = \"text-align: right;\">0.1005</td><td style = \"text-align: right;\">0.0535</td><td style = \"text-align: right;\">0.0235</td><td style = \"text-align: right;\">0.0155</td><td style = \"text-align: right;\">0.016</td><td style = \"text-align: right;\">0.0029</td><td style = \"text-align: right;\">0.0051</td><td style = \"text-align: right;\">0.0062</td><td style = \"text-align: right;\">0.0089</td><td style = \"text-align: right;\">0.014</td><td style = \"text-align: right;\">0.0138</td><td style = \"text-align: right;\">0.0077</td><td style = \"text-align: right;\">0.0031</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">207</td><td style = \"text-align: right;\">0.0303</td><td style = \"text-align: right;\">0.0353</td><td style = \"text-align: right;\">0.049</td><td style = \"text-align: right;\">0.0608</td><td style = \"text-align: right;\">0.0167</td><td style = \"text-align: right;\">0.1354</td><td style = \"text-align: right;\">0.1465</td><td style = \"text-align: right;\">0.1123</td><td style = \"text-align: right;\">0.1945</td><td style = \"text-align: right;\">0.2354</td><td style = \"text-align: right;\">0.2898</td><td style = \"text-align: right;\">0.2812</td><td style = \"text-align: right;\">0.1578</td><td style = \"text-align: right;\">0.0273</td><td style = \"text-align: right;\">0.0673</td><td style = \"text-align: right;\">0.1444</td><td style = \"text-align: right;\">0.207</td><td style = \"text-align: right;\">0.2645</td><td style = \"text-align: right;\">0.2828</td><td style = \"text-align: right;\">0.4293</td><td style = \"text-align: right;\">0.5685</td><td style = \"text-align: right;\">0.699</td><td style = \"text-align: right;\">0.7246</td><td style = \"text-align: right;\">0.7622</td><td style = \"text-align: right;\">0.9242</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.9979</td><td style = \"text-align: right;\">0.8297</td><td style = \"text-align: right;\">0.7032</td><td style = \"text-align: right;\">0.7141</td><td style = \"text-align: right;\">0.6893</td><td style = \"text-align: right;\">0.4961</td><td style = \"text-align: right;\">0.2584</td><td style = \"text-align: right;\">0.0969</td><td style = \"text-align: right;\">0.0776</td><td style = \"text-align: right;\">0.0364</td><td style = \"text-align: right;\">0.1572</td><td style = \"text-align: right;\">0.1823</td><td style = \"text-align: right;\">0.1349</td><td style = \"text-align: right;\">0.0849</td><td style = \"text-align: right;\">0.0492</td><td style = \"text-align: right;\">0.1367</td><td style = \"text-align: right;\">0.1552</td><td style = \"text-align: right;\">0.1548</td><td style = \"text-align: right;\">0.1319</td><td style = \"text-align: right;\">0.0985</td><td style = \"text-align: right;\">0.1258</td><td style = \"text-align: right;\">0.0954</td><td style = \"text-align: right;\">0.0489</td><td style = \"text-align: right;\">0.0241</td><td style = \"text-align: right;\">0.0042</td><td style = \"text-align: right;\">0.0086</td><td style = \"text-align: right;\">0.0046</td><td style = \"text-align: right;\">0.0126</td><td style = \"text-align: right;\">0.0036</td><td style = \"text-align: right;\">0.0035</td><td style = \"text-align: right;\">0.0034</td><td style = \"text-align: right;\">0.0079</td><td style = \"text-align: right;\">0.0036</td><td style = \"text-align: right;\">0.0048</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">208</td><td style = \"text-align: right;\">0.026</td><td style = \"text-align: right;\">0.0363</td><td style = \"text-align: right;\">0.0136</td><td style = \"text-align: right;\">0.0272</td><td style = \"text-align: right;\">0.0214</td><td style = \"text-align: right;\">0.0338</td><td style = \"text-align: right;\">0.0655</td><td style = \"text-align: right;\">0.14</td><td style = \"text-align: right;\">0.1843</td><td style = \"text-align: right;\">0.2354</td><td style = \"text-align: right;\">0.272</td><td style = \"text-align: right;\">0.2442</td><td style = \"text-align: right;\">0.1665</td><td style = \"text-align: right;\">0.0336</td><td style = \"text-align: right;\">0.1302</td><td style = \"text-align: right;\">0.1708</td><td style = \"text-align: right;\">0.2177</td><td style = \"text-align: right;\">0.3175</td><td style = \"text-align: right;\">0.3714</td><td style = \"text-align: right;\">0.4552</td><td style = \"text-align: right;\">0.57</td><td style = \"text-align: right;\">0.7397</td><td style = \"text-align: right;\">0.8062</td><td style = \"text-align: right;\">0.8837</td><td style = \"text-align: right;\">0.9432</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">0.9375</td><td style = \"text-align: right;\">0.7603</td><td style = \"text-align: right;\">0.7123</td><td style = \"text-align: right;\">0.8358</td><td style = \"text-align: right;\">0.7622</td><td style = \"text-align: right;\">0.4567</td><td style = \"text-align: right;\">0.1715</td><td style = \"text-align: right;\">0.1549</td><td style = \"text-align: right;\">0.1641</td><td style = \"text-align: right;\">0.1869</td><td style = \"text-align: right;\">0.2655</td><td style = \"text-align: right;\">0.1713</td><td style = \"text-align: right;\">0.0959</td><td style = \"text-align: right;\">0.0768</td><td style = \"text-align: right;\">0.0847</td><td style = \"text-align: right;\">0.2076</td><td style = \"text-align: right;\">0.2505</td><td style = \"text-align: right;\">0.1862</td><td style = \"text-align: right;\">0.1439</td><td style = \"text-align: right;\">0.147</td><td style = \"text-align: right;\">0.0991</td><td style = \"text-align: right;\">0.0041</td><td style = \"text-align: right;\">0.0154</td><td style = \"text-align: right;\">0.0116</td><td style = \"text-align: right;\">0.0181</td><td style = \"text-align: right;\">0.0146</td><td style = \"text-align: right;\">0.0129</td><td style = \"text-align: right;\">0.0047</td><td style = \"text-align: right;\">0.0039</td><td style = \"text-align: right;\">0.0061</td><td style = \"text-align: right;\">0.004</td><td style = \"text-align: right;\">0.0036</td><td style = \"text-align: right;\">0.0061</td><td style = \"text-align: right;\">0.0115</td><td style = \"text-align: left;\">M</td><td style = \"text-align: right;\">true</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& Column1 & Column2 & Column3 & Column4 & Column5 & Column6 & Column7 & Column8 & Column9 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0.02 & 0.0371 & 0.0428 & 0.0207 & 0.0954 & 0.0986 & 0.1539 & 0.1601 & 0.3109 & $\\dots$ \\\\\n",
       "\t2 & 0.0453 & 0.0523 & 0.0843 & 0.0689 & 0.1183 & 0.2583 & 0.2156 & 0.3481 & 0.3337 & $\\dots$ \\\\\n",
       "\t3 & 0.0262 & 0.0582 & 0.1099 & 0.1083 & 0.0974 & 0.228 & 0.2431 & 0.3771 & 0.5598 & $\\dots$ \\\\\n",
       "\t4 & 0.01 & 0.0171 & 0.0623 & 0.0205 & 0.0205 & 0.0368 & 0.1098 & 0.1276 & 0.0598 & $\\dots$ \\\\\n",
       "\t5 & 0.0762 & 0.0666 & 0.0481 & 0.0394 & 0.059 & 0.0649 & 0.1209 & 0.2467 & 0.3564 & $\\dots$ \\\\\n",
       "\t6 & 0.0286 & 0.0453 & 0.0277 & 0.0174 & 0.0384 & 0.099 & 0.1201 & 0.1833 & 0.2105 & $\\dots$ \\\\\n",
       "\t7 & 0.0317 & 0.0956 & 0.1321 & 0.1408 & 0.1674 & 0.171 & 0.0731 & 0.1401 & 0.2083 & $\\dots$ \\\\\n",
       "\t8 & 0.0519 & 0.0548 & 0.0842 & 0.0319 & 0.1158 & 0.0922 & 0.1027 & 0.0613 & 0.1465 & $\\dots$ \\\\\n",
       "\t9 & 0.0223 & 0.0375 & 0.0484 & 0.0475 & 0.0647 & 0.0591 & 0.0753 & 0.0098 & 0.0684 & $\\dots$ \\\\\n",
       "\t10 & 0.0164 & 0.0173 & 0.0347 & 0.007 & 0.0187 & 0.0671 & 0.1056 & 0.0697 & 0.0962 & $\\dots$ \\\\\n",
       "\t11 & 0.0039 & 0.0063 & 0.0152 & 0.0336 & 0.031 & 0.0284 & 0.0396 & 0.0272 & 0.0323 & $\\dots$ \\\\\n",
       "\t12 & 0.0123 & 0.0309 & 0.0169 & 0.0313 & 0.0358 & 0.0102 & 0.0182 & 0.0579 & 0.1122 & $\\dots$ \\\\\n",
       "\t13 & 0.0079 & 0.0086 & 0.0055 & 0.025 & 0.0344 & 0.0546 & 0.0528 & 0.0958 & 0.1009 & $\\dots$ \\\\\n",
       "\t14 & 0.009 & 0.0062 & 0.0253 & 0.0489 & 0.1197 & 0.1589 & 0.1392 & 0.0987 & 0.0955 & $\\dots$ \\\\\n",
       "\t15 & 0.0124 & 0.0433 & 0.0604 & 0.0449 & 0.0597 & 0.0355 & 0.0531 & 0.0343 & 0.1052 & $\\dots$ \\\\\n",
       "\t16 & 0.0298 & 0.0615 & 0.065 & 0.0921 & 0.1615 & 0.2294 & 0.2176 & 0.2033 & 0.1459 & $\\dots$ \\\\\n",
       "\t17 & 0.0352 & 0.0116 & 0.0191 & 0.0469 & 0.0737 & 0.1185 & 0.1683 & 0.1541 & 0.1466 & $\\dots$ \\\\\n",
       "\t18 & 0.0192 & 0.0607 & 0.0378 & 0.0774 & 0.1388 & 0.0809 & 0.0568 & 0.0219 & 0.1037 & $\\dots$ \\\\\n",
       "\t19 & 0.027 & 0.0092 & 0.0145 & 0.0278 & 0.0412 & 0.0757 & 0.1026 & 0.1138 & 0.0794 & $\\dots$ \\\\\n",
       "\t20 & 0.0126 & 0.0149 & 0.0641 & 0.1732 & 0.2565 & 0.2559 & 0.2947 & 0.411 & 0.4983 & $\\dots$ \\\\\n",
       "\t21 & 0.0473 & 0.0509 & 0.0819 & 0.1252 & 0.1783 & 0.307 & 0.3008 & 0.2362 & 0.383 & $\\dots$ \\\\\n",
       "\t22 & 0.0664 & 0.0575 & 0.0842 & 0.0372 & 0.0458 & 0.0771 & 0.0771 & 0.113 & 0.2353 & $\\dots$ \\\\\n",
       "\t23 & 0.0099 & 0.0484 & 0.0299 & 0.0297 & 0.0652 & 0.1077 & 0.2363 & 0.2385 & 0.0075 & $\\dots$ \\\\\n",
       "\t24 & 0.0115 & 0.015 & 0.0136 & 0.0076 & 0.0211 & 0.1058 & 0.1023 & 0.044 & 0.0931 & $\\dots$ \\\\\n",
       "\t25 & 0.0293 & 0.0644 & 0.039 & 0.0173 & 0.0476 & 0.0816 & 0.0993 & 0.0315 & 0.0736 & $\\dots$ \\\\\n",
       "\t26 & 0.0201 & 0.0026 & 0.0138 & 0.0062 & 0.0133 & 0.0151 & 0.0541 & 0.021 & 0.0505 & $\\dots$ \\\\\n",
       "\t27 & 0.0151 & 0.032 & 0.0599 & 0.105 & 0.1163 & 0.1734 & 0.1679 & 0.1119 & 0.0889 & $\\dots$ \\\\\n",
       "\t28 & 0.0177 & 0.03 & 0.0288 & 0.0394 & 0.063 & 0.0526 & 0.0688 & 0.0633 & 0.0624 & $\\dots$ \\\\\n",
       "\t29 & 0.01 & 0.0275 & 0.019 & 0.0371 & 0.0416 & 0.0201 & 0.0314 & 0.0651 & 0.1896 & $\\dots$ \\\\\n",
       "\t30 & 0.0189 & 0.0308 & 0.0197 & 0.0622 & 0.008 & 0.0789 & 0.144 & 0.1451 & 0.1789 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m208×62 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Column1 \u001b[0m\u001b[1m Column2 \u001b[0m\u001b[1m Column3 \u001b[0m\u001b[1m Column4 \u001b[0m\u001b[1m Column5 \u001b[0m\u001b[1m Column6 \u001b[0m\u001b[1m Column7 \u001b[0m\u001b[1m Column8 \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "     │\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │  0.02     0.0371   0.0428   0.0207   0.0954   0.0986   0.1539   0.1601  ⋯\n",
       "   2 │  0.0453   0.0523   0.0843   0.0689   0.1183   0.2583   0.2156   0.3481\n",
       "   3 │  0.0262   0.0582   0.1099   0.1083   0.0974   0.228    0.2431   0.3771\n",
       "   4 │  0.01     0.0171   0.0623   0.0205   0.0205   0.0368   0.1098   0.1276\n",
       "   5 │  0.0762   0.0666   0.0481   0.0394   0.059    0.0649   0.1209   0.2467  ⋯\n",
       "   6 │  0.0286   0.0453   0.0277   0.0174   0.0384   0.099    0.1201   0.1833\n",
       "   7 │  0.0317   0.0956   0.1321   0.1408   0.1674   0.171    0.0731   0.1401\n",
       "   8 │  0.0519   0.0548   0.0842   0.0319   0.1158   0.0922   0.1027   0.0613\n",
       "   9 │  0.0223   0.0375   0.0484   0.0475   0.0647   0.0591   0.0753   0.0098  ⋯\n",
       "  10 │  0.0164   0.0173   0.0347   0.007    0.0187   0.0671   0.1056   0.0697\n",
       "  11 │  0.0039   0.0063   0.0152   0.0336   0.031    0.0284   0.0396   0.0272\n",
       "  ⋮  │    ⋮        ⋮        ⋮        ⋮        ⋮        ⋮        ⋮        ⋮     ⋱\n",
       " 199 │  0.0238   0.0318   0.0422   0.0399   0.0788   0.0766   0.0881   0.1143\n",
       " 200 │  0.0116   0.0744   0.0367   0.0225   0.0076   0.0545   0.111    0.1069  ⋯\n",
       " 201 │  0.0131   0.0387   0.0329   0.0078   0.0721   0.1341   0.1626   0.1902\n",
       " 202 │  0.0335   0.0258   0.0398   0.057    0.0529   0.1091   0.1709   0.1684\n",
       " 203 │  0.0272   0.0378   0.0488   0.0848   0.1127   0.1103   0.1349   0.2337\n",
       " 204 │  0.0187   0.0346   0.0168   0.0177   0.0393   0.163    0.2028   0.1694  ⋯\n",
       " 205 │  0.0323   0.0101   0.0298   0.0564   0.076    0.0958   0.099    0.1018\n",
       " 206 │  0.0522   0.0437   0.018    0.0292   0.0351   0.1171   0.1257   0.1178\n",
       " 207 │  0.0303   0.0353   0.049    0.0608   0.0167   0.1354   0.1465   0.1123\n",
       " 208 │  0.026    0.0363   0.0136   0.0272   0.0214   0.0338   0.0655   0.14    ⋯\n",
       "\u001b[36m                                                 54 columns and 187 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insertcols!(data, :Mine => data[:, 61].==\"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efa393f",
   "metadata": {},
   "source": [
    "Once the data is loaded in the DataFrame for the checking proposes and that any posible process has been applied on the data. As in previous tutorials, the data has to be put on a Matrix form, such as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "590ea8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Matrix(data[!, 1:60]);\n",
    "output_data = data[!, :Mine];\n",
    "\n",
    "@assert input_data isa Matrix\n",
    "@assert output_data isa BitVector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a148c7",
   "metadata": {},
   "source": [
    "It is worth to mention that in a DataFrame when a set of lines is queried such as in the case of the `X`, the results is also a DataFrame. Therefore, in order to applied the remaining operations it is needed to applied the `Matrix` function to retrive a matrix where the previous operations can be used as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d272d3b3",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Now, the data is loaded and converted to the usual types. Now you should be able to apply in the next section and make asplit of the dataset in two subset, test and training, and apply the corresponding normalization. Put the code on the following section to perform both operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e4831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_input, train_output, test_input, test_output = #TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbe5ef",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "As mentioned above, ensembles are a set of \"weaker\" classifiers that allow us to later overcome their limits by joining them together. That is why, before starting with ensembles, it will be necessary to have some reference models that will later be joined together in a meta-classifier. In the following example, some simple models, from `scikit-learn` library, are trained: an SVM with RBF kernel, a Linear Regression, a Naïve Bayes and a Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b0a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ScikitLearn\n",
    "\n",
    "@sk_import svm:SVC\n",
    "@sk_import tree:DecisionTreeClassifier\n",
    "@sk_import linear_model:LogisticRegression\n",
    "@sk_import naive_bayes:GaussianNB \n",
    "\n",
    "#Define the models to train\n",
    "models = Dict( \"SVM\" => SVC(probability=true), \n",
    "         \"LR\" =>LogisticRegression(),\n",
    "         \"DT\"=> DecisionTreeClassifier(max_depth=4),\n",
    "         \"NB\"=> GaussianNB())\n",
    "\n",
    "base_models =  [ name for name in keys(models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a595d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the training for each model and calculate the test values (accuracy)\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    fit!(model,train_input, train_output)\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ecb8c",
   "metadata": {},
   "source": [
    "## Combining weak models in an ensemble\n",
    "\n",
    "When it comes to combining the models, there are different strategies depending on the task of the model, i.e. whether we are classifying or regressing. In this particular case we are going to focus on classification, although for regression it would be similar, but the continuous nature of the values should be taken into account when combining the outputs.\n",
    "\n",
    "Regarding the combination of the classification, there are mainly two ways to combine the outputs of several classifiers. These combinations are called Majority voting and Weighted majority voting.\n",
    "\n",
    "### Majority Voting\n",
    "Although also known as Hard Voting, as the name suggests, they are based on selecting the most voted option among the predicted ones among the different models. The implementation available in scikit learn makes a sum of the predictions for each of the classes and then averages these estimates. The option selected by majority among the \"experts\" of which the emsemble consists is the one selected. In this way, the problem could be solved taking into account different results or points of view on the problem. See an example in the code below of constructing such a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sk_import ensemble:VotingClassifier\n",
    "\n",
    "#Define the metaclassifier based on the base_models\n",
    "models[\"Ensemble (Hard Voting)\"] = VotingClassifier(estimators = [(name,models[name]) for name in base_models], \n",
    "                                                   n_jobs=-1)\n",
    "fit!(models[\"Ensemble (Hard Voting)\"], train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3971c",
   "metadata": {},
   "source": [
    "As can be seen, while it does not improve on the best of the component models, this is because, firstly, this is not a particularly complex problem. In addition, another problem is that we rely equally on all models when deciding on the response class. To solve this problem, it is possible to make it so that not all models are of equal importance, as we will see in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf78117f",
   "metadata": {},
   "source": [
    "### Weigthed Mayority Voting \n",
    "As mentioned in the previous section, one of the problems of the classical *emsemble* model is that all outcomes are weighted equally and in each of the \"weak\" models only the most voted option is taken into account. To solve this, one of the proposals is the use of a weighting in the decision weights. This is because one model may be better than another or more reliable. In order to reflect this point, the output can be modified by multiplying it by a confidence factor within the rule used to make the decisions. This weighting procedure is sometimes also referred to as *Soft Voting* in contrast to *Hard Voting* or unweighted voting. Imagine that each of the classifiers is assigned the same weight, i.e. {1,1,1}. In an example like the following with an SVM, a Logarithmic regression and a Bayes-based model we would have the following outputs.\n",
    "\n",
    "|Classifier\t     |Mine\t        |Rock          |\n",
    "| :------------- | :----------: | -----------: |\n",
    "|SVM         \t | 0.9\t    | 0.1      |\t\n",
    "|LR         \t | 0.3\t    | 0.7      |\t\n",
    "|NB         \t | 0.2\t    | 0.8      |\n",
    "|Soft Voting      |0.47\t        |0.63          |\t\n",
    "\n",
    "Therefore, the selected class would be the Rock class since all models weigh the same in the decision making process when averaging. In contrast, if we know that one of the models is better, we can weight the response of that model. Imagine in the previous example if you knew that SVM is usually much better than the other two for this particular problem. In that case, you can increase its weight as seen below in order to take that model more into account. With the same example, but with SVM's answer being larger, the results would be:\n",
    "\n",
    "|Classifier\t     |Mine\t        |Rock          |\n",
    "| :------------- | :----------: | -----------: |\n",
    "|SVM         \t |2 * 0.9\t    |2 * 0.1      |\t\n",
    "|LR         \t |1 * 0.3\t    |1 * 0.7      |\t\n",
    "|NB         \t |1 * 0.2\t    |1 * 0.8      |\n",
    "|Soft Voting      |0.575\t        |0.425          |\n",
    "\n",
    "As can be seen from the results, if we have a higher quality model, the outputs of this model will be taken into account more in terms of making the corresponding decision.\n",
    "\n",
    "To implement this type of behaviour, you can simply add two additional parameters to the `VotingClassifier` function that was previously used to weight the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260da3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"Ensemble (Soft Voting)\"] = VotingClassifier(estimators = [(name,models[name]) for name in base_models], \n",
    "                                                   n_jobs=-1, voting=\"soft\",weights=[1,2,2,1])\n",
    "fit!(models[\"Ensemble (Soft Voting)\"],train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,train_input, train_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa26ee5d",
   "metadata": {},
   "source": [
    "As you can see, the results are better when you combine several models that give good results. In fact, this procedure is the basis of other techniques such as the *Random Forest* that we will see a little later in this tutorial. The models to be used are the other key to the creation of _ensemble_, in the next section we will see the most common strategies for the creation of the models.\n",
    "\n",
    "The adjustment of these weights can be done in many different ways, for example, it can be done manually as we have done in the previous example. Another alternative would be to use a gradient descent technique to adjust them as if it were a neural network or an SVM. Another possibility is to use the fit value on the validation set (in this case a dataset has not been reserved for this purpose) as the weight of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be268b",
   "metadata": {},
   "source": [
    "### Question\n",
    "We have perform every single test with a hold-out strategy, however, as it was appointed in a previous session, the application of a cross-validation approach is prefered to cut the dependency on the selection of the samples. In this case you could think that there are two different approaches one is apply the cross-validation to each model, choose the better one and combine those in a single ensemble. The other way arround would be applying the cross-validation at ensemble level before training the models. Which one is correct and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2fcbb5",
   "metadata": {},
   "source": [
    "`Answer here`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2b304",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "\n",
    "This last approach to combining the models can be considered as a variant of Soft Voting. As mentioned in that section, soft voting allows the weights of each of the models to be fixed and this can be adjusted with a decaying gradient technique. Stacking is usually identified as creating a classification technique superior to a linear regression (which is what Soft Voting does) such as an ANN to combine the models.\n",
    "\n",
    "Thus, as has been done previously, the outputs of the different techniques could be taken and used as inputs to another classification model, allowing for the adjustment of the weights and the non-linear combinations of the responses of each one.\n",
    "\n",
    "You can see an example or this in the following code, which uses the implementation on `scikit=learn` whcih uses an SVC as compbining model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70391c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@sk_import ensemble:StackingClassifier\n",
    "\n",
    "models[\"Ensemble (Stacking)\"] = StackingClassifier(estimators=[(name,models[name]) for name in base_models],\n",
    "    final_estimator=SVC(probability=true), n_jobs=-1)\n",
    "fit!(models[\"Ensemble (Stacking)\"], train_input, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed598b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,train_input, train_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9273829",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "One of the key elements that has not yet been addressed is the creation of the models that will compose the meta-classifier. So far, the approach that has been followed is not very adequate as the input dataset for all models is the same. This has the effect of an obvious lack of diversity in the models since whichever model we create, it will have the same information or \"point of view\" as the others. However, this is not the usual practice. Instead, the set of input patterns is usually divided into smaller sets with which to train one or more techniques in order to reduce the computational cost on the one hand, and to increase the diversity of the models on the other. It is necessary to remember at this point that \"weak\" models do not have to be perfect in all classes and do not even have to cover all possibilities, only models that are quick to train and offer a more or less consistent output.\n",
    "\n",
    "As for the way in which to partition the data for the creation of the models, most approaches usually consider two main approaches known as *Bagging* and *Boosting*. In the following, these two approaches will be briefly described.\n",
    "\n",
    "### Bagging or boostrap aggregation\n",
    "The technique known as _Bagging_ or selection with replacement was proposed by Breitman in 1996. It is based on the development of multiple models which can be trained in parallel. The key element of these models is that each model is trained on a subset of the training set. This subset of data is drawn randomly with replacement. This last point is particularly important because once an example has been selected from the possibilities, it is placed back among the possibilities so that it can be selected either in the subset being built, or in the subsets of the other models, i.e. non-disjoint sets of examples are created.\n",
    "\n",
    "![Bagging Example](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Ensemble_Bagging.svg/440px-Ensemble_Bagging.svg.png)\n",
    "\n",
    "The result is that \"experts\" are created on specialised data and depending on the partition. While common, or more frequent, data is correctly covered by all models, it is also true that less frequent data tends not to be in all partitions and may not be covered in all cases. Thus, you would get models that would be more specialised in certain data or have a different point of view, that would be experts in a particular region of the search space.\n",
    "\n",
    "Although it will be discussed in more detail later, a well-known technique that uses this approach for the construction of its \"weak\" models is RandomForest. It builds the decision trees that make up the metaclassifier in this way. Any classifier can be used as the basis of a *Bagging* with the class [BaggingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html). \n",
    "\n",
    "For example, in the following code, 10 SVM for classication has been chosen as weak models. Each of those models habe been trained on only 50% of the training patterns, and therefore the variance among them should be increased.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7750d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sk_import svm:SVC\n",
    "@sk_import ensemble:BaggingClassifier\n",
    "\n",
    "models[\"Bagging (SVC)\"] = BaggingClassifier(base_estimator=SVC(),n_estimators=10, max_samples=0.50, n_jobs=-1)\n",
    "fit!(models[\"Bagging (SVC)\"], train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,train_input, train_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5787a56",
   "metadata": {},
   "source": [
    "As an alternative to extracting complete examples, a vertical partition of the training _dataset_ could be performed, thus extracting features. To implement this alternative, in the `BaggingClassifier` function, the parameter *max_features* must be defined. This approach is used when the number of features is particularly high in order to create simpler models that do not use all the information that is often redundant. It should be noted that this feature extraction procedure for models is done without replacement, i.e. features extracted for one classifier are not re-entered into the list of possibilities until the set for the next classifier is created.\n",
    "\n",
    "### Boosting\n",
    "The other major family of techniques for ensemble metamodelling is what is known as *Boosting*. In this case, the approach is slightly different, since the aim is to create a chain of classifiers. The key element of this type of classifier is to find that each new classifier is more specialised in the patterns that the previous models have missed. Therefore, as in the previous case, a subset of patterns is selected from the original set. However, this process is done sequentially and without replacement. This point is crucial since, as mentioned above, the idea is to eliminate those patterns that are already correctly classified and to obtain more specific models that concentrate on those examples that are less frequent or that have been incorrectly classified in a previous step. Thus, as in *Bagging*, the underlying idea of this approach is that not all models have to have all patterns as a basis, but unlike _Bagging_, this process is linear because of the dependency in the construction of the models. \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Ensemble_Boosting.svg/1920px-Ensemble_Boosting.svg.png\" alt=\"Boosting examples\" width=\"600\"/>\n",
    "\n",
    "Subsequently, to obtain the combination of the models, the Majority Vote with weights is used. In this approach, the weights are established with an iterative approximation system. There are many examples that use this type of technique, such as [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) or [Gracient Tree Boosting](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html). In both cases what is done is an adjustment of the weights with a technique based on the Descending Gradient. \n",
    "\n",
    "In the case of AdaBoost, the algorithm starts by giving a weight to all the instances of the training set. With this weighted set, a classifier is trained with the original data. Depending on the errors made, the weights of the original set are adjusted and a new copy of the classifier is trained, but on the adjusted data, which will focus more on the instances that have been classified incorrectly. In the case of `scikit learn`, the algorithm implemented is known as [AdaBoost-SAMME](https://hastie.su.domains/Papers/SII-2-3-A8-Zhu.pdf) proposed by Zhu et.al. in 2009. As a particularity of this implementation, the *loss* function used is an exponential one. This is the one that will be used to calculate the weighting of the errors made, as well as the weight of the classifiers in the meta-classifier. In general terms, the output will be the most voted by the classifiers based on the weighting of each of them. \n",
    "\n",
    "Gradient Tree Boosting is a different approach to the use of Boosting. It builds a tree where the nodes of the tree set the criteria for, for example, in the case of classification refer to the `logistic-likelihood` of a given pattern. In this way, each of the nodes of the tree makes a classification which is adjusted on the basis of the residual errors that are made by adjusting the weights of the different classifiers in the tree. This division is carried out for each of the available features, performing a recursive procedure by training several classifiers in this way. Subsequently, to make the decision, it is based on the responses of the classifiers it has passed through. The main difference with AdaBoost is that in this case the output is the probabilities of the classes which are summed to give the most likely answer rather than the answer over the instances.\n",
    "\n",
    "Below, we see an approach with an example of using these two metaclassifiers that make use of _Boosting_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sk_import ensemble:(AdaBoostClassifier, GradientBoostingClassifier)\n",
    "\n",
    "models[\"Ada\"] = AdaBoostClassifier(n_estimators=30)\n",
    "fit!(models[\"Ada\"], train_input, train_output)\n",
    "\n",
    "models[\"GTB\"] = GradientBoostingClassifier(n_estimators=30, learning_rate=1.0, max_depth=2, random_state=0)\n",
    "fit!(models[\"GTB\"], train_input, train_output)\n",
    "\n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43fc04b",
   "metadata": {},
   "source": [
    "### Question\n",
    "In a similar way as in the cross-validation section, develop a funtion to train ensembles. The function called trainClassEmsemble, would also follow an stratified cross-validation. As a quick remember of the steps need to cover in the function:\n",
    "1. Create a vector with k elements, which will contain the test results of the cross-validation process with the selected metric.  \n",
    "\n",
    "2. Make a loop with k iterations (k folds) where within each iteration from the matrices of desired inputs and outputs, by means of the vector of indices resulting from the previous function, 4 matrices are created: desired inputs and outputs for training and test. \n",
    "\n",
    "3. Within this another loop, add a call to generate the models, which can be any of the ones used in Unit 6. \n",
    "\n",
    "4. Train those models by using the corresponding training set, i. e., the remaining K subsets non used for testing.\n",
    "\n",
    "5. In case a validation set is needed, e.g. wi, split the training set into two parts. To do this, use the holdOut function. \n",
    "\n",
    "4. Build the ensemble following one of the strategies described above (any of them) and calculate the test.  \n",
    "\n",
    "\n",
    "6. Finally, provide the result of averaging the values of these vectors for each metric together with their standard deviations. \n",
    "\n",
    "As a result of this call, at least the test value in the selected metric(s) should be returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55290ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "function trainClassEnsemble(estimators::AbstractArray{Symbol,1}, \n",
    "        modelsHyperParameters:: AbstractArray{Dict, 1},     \n",
    "        trainingDataset::Tuple{AbstractArray{<:Real,2}, AbstractArray{Bool,2}},    \n",
    "        kFoldIndices::     Array{Int64,1})\n",
    "    #TODO\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265be0c",
   "metadata": {},
   "source": [
    "### Question\n",
    "Repeted the previous function, but this time allowing to pass only one estimator as base. it can be replicated and pass to the previous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "function trainClassEnsemble(baseEstimator::Symbol, \n",
    "        modelsHyperParameters::Dict,\n",
    "        NumEstimators::Int=100,\n",
    "        trainingDataset::Tuple{AbstractArray{<:Real,2}, AbstractArray{Bool,2}},     \n",
    "        kFoldIndices::     Array{Int64,1})\n",
    "    #TODO\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840ea28",
   "metadata": {},
   "source": [
    "## Techniques integrating the Ensemble approach\n",
    "\n",
    "Some of the best-known and currently used algorithms are based on this type of approach. Among these approaches, perhaps the most famous and widely used are those based on the generation of simple Decision Tress (DT). The reason for the use of the trees is their easy interpretation, as well as the speed of calculation and training. In the following we will see the two approaches known today in this sense, ***Random Forest*** and ***XGBoost***.\n",
    "\n",
    "\n",
    "### Random Forest\n",
    "This algorithm, proposed by Breitman and Cutler in 2006 on the basis of an earlier publication by Ho in 1995 (_Random Subspaces_), is the paradigm ensemble technique. The algorithm joins into an ensemble a set of simple classifiers that take the form of Decision Trees. These classifiers are trained following a **bagging** approach, and can therefore be trained in parallel. Combining the output of the algorithms is done for classification problems by means of the most voted option among the \"experts\" or, if it is a regression problem, by means of the arithmetic mean of the answers. \n",
    "\n",
    "It is an algorithm that needs the adjustment of very few hyperparameters to obtain very good results in almost any type of problem. In general, the most important value is the number of estimators and therefore the number of partitions to be made of the training set. Several authors point out that this number of estimators should be *$\\sqrt{\\textrm{#feature}}$* for classification problems, and *$\\frac{\\textrm{#feature}}{3}$* for regression problems. However, he also points out that the technique would saturate between 500 and 1000 trees and no matter how much it is increased it would not improve results. However, this last point has only been tested empirically on certain data sets and, therefore, should be taken with caution as it has no mathematical justification.\n",
    "\n",
    "In addition to the usual bagging process, the Random Forest also includes a second splitting mechanism. Once the patterns that will form part of the training set of the decision tree have been selected, only a subset of random features (*features*) are available for each node of the tree. This increases the diversity of the trees in the forest and focuses on the overall performance with a small variance in the results. This mechanism makes it possible to quantitatively assess the individual performance of each tree in the forest and its variables. Therefore, the importance of each variable can be measured. This measure that calibrates the participation of each variable in the nodes of the tree in decision-making is called impurity and measures the difference between the different branches of the tree when partitioning the examples. Sometimes, this same measure is used as a measure for the selection of variables by taking the measure in all the trees of the forest of the participation and importance by means of a filtering like those seen in the previous unit.\n",
    "\n",
    "For the calculation of this measure of impurity, there are different approaches. For example, `scikit learn` uses a measure it calls **Gini**. The latter is the probability of misclassifying a randomly chosen item in the dataset if it were randomly labelled according to the distribution of classes in the dataset. It is calculated as:\n",
    "$$G = \\sum_{i=1}^C p(i) * (1 - p(i))$$\n",
    "\n",
    "where $C$ is the number of classes and $p(i)$ is the probability of randomly selecting an element of class $i$. A good example of how to calculate the impurity of the branches can be seen in the following [link](https://victorzhou.com/blog/gini-impurity/)\n",
    "\n",
    "Next, on the example used in this unit, we will run a *Random Forest* model with the `scikit learn` implementation. The most important parameters of this implementation are:\n",
    "\n",
    "- ***n_estimator***, marking the number of trees to be generated or the number of *bagging* partitions.\n",
    "- ***criterion***, measure of node impurity. By default Gini is used, but it can be changed to gained entropy.\n",
    "- max_depth***, allows to limit the maximum depth of the trees in order to limit the number of variables to use.\n",
    "- ***min_sample_split***, for each decision tree, how many patterns are needed to perform an internal split in the *Decision Trees*.\n",
    "- bootstrap***, you can use the *bagging* or *bootstrap* approach to build the trees but if this property is false, then it uses the whole training set to generate the trees. In case of a True value, the following properties are taken into account:\n",
    "    + ***max_samples***, number of examples to extract from the original set to build the training set of the estimator, the default value is equal to the number of patterns but remember that the same can be extracted several times as it is a selection with replacement giving variability.\n",
    "    + ***oob_score***, *out of bag* measure for estimating generalisation. Those samples that have not been part of the training of an estimator can be used to calculate a validation measure, and averaged across all estimators to see how general the constructed forest is.\n",
    "    \n",
    "For example, the code below shows how to use the implementation in `scikit learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668be4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@sk_import ensemble:RandomForestClassifier\n",
    "\n",
    "models[\"RF\"] = RandomForestClassifier(n_estimators=8, max_depth=nothing,\n",
    "                                    min_samples_split=2, n_jobs=-1)\n",
    "fit!(models[\"RF\"], train_input, train_output)\n",
    "    \n",
    "for key in keys(models)\n",
    "    model = models[key]\n",
    "    acc = score(model,test_input, test_output)\n",
    "    println(\"$key: $(acc*100) %\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbe372",
   "metadata": {},
   "source": [
    "In this approach, the number of estimators has been defined following the aforementioned rule of $\\sqrt{\\textrm{#features}}$. In this case, as there are few estimators and few patterns, the results may vary quite a lot depending on the type of partitions obtained.\n",
    "\n",
    "Then, once the model has been trained, the level of impurity obtained for each of the frequencies calculated with the Gini algorithm can be computed as an average of those obtained among the trees that make up the forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea85f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = bar(y=1:60,models[\"RF\"].feature_importances_, orientation=:horizontal, legend = false)\n",
    "xlabel!(p,\"Gini Gain\")\n",
    "ylabel!(p,\"Fearure\")\n",
    "title!(\"Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4feb1ec",
   "metadata": {},
   "source": [
    "It should be pointed out that, as can be seen in the graph, this value determines that most of the information is concentrated in some of the frequencies used. This is why a filtering of the information such as the ones we will see in the next session could be carried out based on this value. \n",
    "\n",
    "### XGBoost (eXtreme Gradient Boosting)\n",
    "\n",
    "Finally, in this last section, Gradient Boosting should be mentioned again, specifically an implementation that in recent years has become very famous for its versatility and speed. This implementation is known as ***XGBoost (eXtreme Gradient Boosting)*** , which has stood out especially in competitions such as the Kaggle platform for its speed in obtaining results and robustness. \n",
    "\n",
    "The ***XGBoost*** will be a similar ensemble to Random Forest but uses a different base classifier known as CART (classification and regression trees) instead of *Decision Trees*. This change comes from the need for the algorithm to obtain the probability of the decisions, as was the case with *Gradient Tree Boosting*. The other fundamental change in this algotimo, since it is based on *Gradient Tree Boosting*, is the change from *bagging* to *boosting* strategy for the creation of the classifier training sets.\n",
    "\n",
    "Subsequently, this technique performs an additive training approach whose weights are adjusted based on a **Declining Gradient** on a *loss* function to be defined. By adding the *loss* function with the regularisation term, the second derivative of the functions can be calculated in order to update the classification weights of the different trees. The calculation of this gradient thus allows the adjustment of the values of the classifiers that are generated following a given one in order to allow the weights to focus attention on the patterns that are incorrectly classified. The mathematical details of the implementation can be found in this [link](https://xgboost.readthedocs.io/en/stable/tutorials/model.html).\n",
    "\n",
    "Unlike the other approaches we have seen, the `xgboost` is not currently implemented in `scikit learn`. For this reason, the reference version must be installed if it is not already present on the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03972c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.7/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg;\n",
    "Pkg.add(\"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e0c0f",
   "metadata": {},
   "source": [
    "After that installation, the library could be used as shown in the following example. Unlike other implementations, the Julia implementation supports Julia Array, SparseMatrixCSC, libSVM format text and XGBoost binary file as input.  Althouugh the vastly options given by Julia libraría in deep to change internaly to the format [LIBSVM](https://xgboost.readthedocs.io/en/stable/tutorials/input_format.html) as any other library. This library has not all the posibilities and, more especificl, the BitVector is not supported nowadays in their function `DMatrix`. So, an small change in the format is required in order to use the library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7fd5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using XGBoost;\n",
    "\n",
    "train_input = input_data\n",
    "train_output = output_data\n",
    "\n",
    "test_input = input_data\n",
    "test_output = output_data\n",
    "\n",
    "train_output_asNumber= Vector{Number}(train_output);\n",
    "\n",
    "@assert train_output_asNumber isa Vector{Number}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad57fb4",
   "metadata": {},
   "source": [
    "Once this data adaptation is done, you can proceed with the training of a model from the `xgboost` library. To do so, it is only necessary to call the function train with the corresponding parameters. Among these parameters, the most important are:\n",
    "\n",
    "- **eta**, term that will determine the compression of the weights after each new stage of *boosting*. It takes values between 0 and 1.\n",
    "- **max_depth**, maximum depth of the trees has by default a value of 6, increasing it will allow more complex models.\n",
    "- **gamma**, parameter that controls the minimum loss reduction necessary to perform a new partition on a leaf node of the tree. The higher it is, the more conservative it will be\n",
    "- **alpha** and **lambda**, are the parameters that control the L1 and L2 regulation respectively.\n",
    "- **objective**, sets the loss function to be used which can be one of the predefined ones, which can be consulted in this [link](https://xgboost.readthedocs.io/en/stable/parameter.html#parameters-for-tree-booster)\n",
    "\n",
    "Further it is only necessary to set the maximum number of iterations of the boosting process as shown in the following example with 20 rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec905d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: XGBoost: starting training.\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:429\n",
      "┌ Info: [1]\ttrain-rmse:0.06737216276580736\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [2]\ttrain-rmse:0.04229933776157622\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [3]\ttrain-rmse:0.02381229156916128\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [4]\ttrain-rmse:0.01432480955123462\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [5]\ttrain-rmse:0.00896001599832029\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [6]\ttrain-rmse:0.00621309809925985\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [7]\ttrain-rmse:0.00388202769954551\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [8]\ttrain-rmse:0.00218962833158029\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [9]\ttrain-rmse:0.00152244579715848\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [10]\ttrain-rmse:0.00082427556746339\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: Training rounds complete.\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[35m╭──── \u001b[1m\u001b[36mXGBoost.Booster\u001b[22m\u001b[39m\u001b[35m\u001b[35m ─────────────────────────────────────────────────────────╮\u001b[39m\u001b[0m\u001b[39m\u001b[35m\n",
       "\u001b[0m\u001b[35m│\u001b[39m\u001b[0m  \u001b[1m\u001b[33mFeatures:\u001b[22m\u001b[39m 60 (unknown names)                                                \u001b[0m\u001b[35m│\u001b[39m\u001b[0m\n",
       "\u001b[0m\u001b[35m│\u001b[39m\u001b[0m  \u001b[38;2;155;179;224m                         \u001b[39m                                                   \u001b[0m\u001b[35m│\u001b[39m\u001b[0m\n",
       "\u001b[0m\u001b[35m│\u001b[39m\u001b[0m  \u001b[38;2;155;179;224m \u001b[39m\u001b[0m\u001b[1m\u001b[32m  Parameter  \u001b[22m\u001b[39m\u001b[38;2;155;179;224m \u001b[39m\u001b[0m\u001b[1m\u001b[32m  Value  \u001b[22m\u001b[39m\u001b[38;2;155;179;224m \u001b[39m\u001b[0m                                                   \u001b[0m\u001b[35m│\u001b[39m\u001b[0m\n",
       "\u001b[0m\u001b[35m│\u001b[39m\u001b[0m  \u001b[38;2;155;179;224m ─────────────────────── \u001b[39m                                                   \u001b[0m\u001b[35m│\u001b[39m\u001b[0m\n",
       "\u001b[0m\u001b[35m│\u001b[39m\u001b[0m  \u001b[38;2;155;179;224m \u001b[39m\u001b[0m\u001b[1m\u001b[33m     eta     \u001b[22m\u001b[39m\u001b[38;2;155;179;224m \u001b[39m\u001b[0m\u001b[22m    1    \u001b[22m\u001b[38;2;155;179;224m \u001b[39m\u001b[0m                                                   \u001b[0m\u001b[35m│\u001b[39m\u001b[0m\n",
       "\u001b[0m\u001b[35m│\u001b[39m\u001b[0m  \u001b[38;2;155;179;224m                         \u001b[39m                                                   \u001b[0m\u001b[35m│\u001b[39m\u001b[0m\n",
       "\u001b[0m\u001b[35m│\u001b[39m\u001b[0m  \u001b[38;2;155;179;224m \u001b[39m\u001b[0m\u001b[1m\u001b[33m  max_depth  \u001b[22m\u001b[39m\u001b[38;2;155;179;224m \u001b[39m\u001b[0m\u001b[22m    6    \u001b[22m\u001b[38;2;155;179;224m \u001b[39m\u001b[0m                                                   \u001b[0m\u001b[35m│\u001b[39m\u001b[0m\n",
       "\u001b[0m\u001b[35m│\u001b[39m\u001b[0m  \u001b[38;2;155;179;224m                         \u001b[39m                                                   \u001b[0m\u001b[35m│\u001b[39m\u001b[0m\n",
       "\u001b[0m\u001b[35m│\u001b[39m\u001b[0m  \u001b[38;2;155;179;224m \u001b[39m\u001b[0m\u001b[1m\u001b[33m   rounds    \u001b[22m\u001b[39m\u001b[38;2;155;179;224m \u001b[39m\u001b[0m\u001b[22m   20    \u001b[22m\u001b[38;2;155;179;224m \u001b[39m\u001b[0m                                                   \u001b[0m\u001b[35m│\u001b[39m\u001b[0m\n",
       "\u001b[0m\u001b[35m│\u001b[39m\u001b[0m  \u001b[38;2;155;179;224m                         \u001b[39m                                                   \u001b[0m\u001b[35m│\u001b[39m\u001b[0m\n",
       "\u001b[35m╰──── \u001b[34mboosted rounds: 10\u001b[39m\u001b[35m\u001b[35m ──────────────────────────────────────────────────────╯\u001b[39m\u001b[0m\u001b[39m\u001b[35m\u001b[0m\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_data = DMatrix(train_input, label=train_output_asNumber)\n",
    "\n",
    "model = xgboost(svm_data, rounds=20, eta = 1, max_depth = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275ed94",
   "metadata": {},
   "source": [
    "On the folllowing piece of code, several parameter as pass as a dictionary and two differnt metrics are calculated. First, error refers to the incorrect classified ones over the total amount and the second one is the Area Under Curbe ROC (AUC).\n",
    "\n",
    "### Question\n",
    "Which is the canonical name of the first measure that is been monitorized?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f5411",
   "metadata": {},
   "source": [
    "`Answer here`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40ab769b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: XGBoost: starting training.\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:429\n",
      "┌ Info: [1]\ttrain-rmse:0.36185209446173100\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [2]\ttrain-rmse:0.26414494265222116\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [3]\ttrain-rmse:0.19957024552112126\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [4]\ttrain-rmse:0.14644661621529045\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [5]\ttrain-rmse:0.10882041020739337\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [6]\ttrain-rmse:0.08185088561861538\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [7]\ttrain-rmse:0.06332960976181366\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [8]\ttrain-rmse:0.05086767457414432\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [9]\ttrain-rmse:0.04003805944630668\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: [10]\ttrain-rmse:0.03208189242795521\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:306\n",
      "┌ Info: Training rounds complete.\n",
      "└ @ XGBoost /home/quique/.julia/packages/XGBoost/TVCOs/src/booster.jl:431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "208-element Vector{Float32}:\n",
       " 0.018040953\n",
       " 0.04299605\n",
       " 0.014163459\n",
       " 0.017609742\n",
       " 0.08954437\n",
       " 0.022500241\n",
       " 0.060126692\n",
       " 0.08999658\n",
       " 0.039912917\n",
       " 0.010365006\n",
       " 0.023115817\n",
       " 0.042595398\n",
       " 0.023901308\n",
       " ⋮\n",
       " 0.98655134\n",
       " 0.9917211\n",
       " 0.9917211\n",
       " 0.98556274\n",
       " 0.98655134\n",
       " 0.9917211\n",
       " 0.9917211\n",
       " 0.98655134\n",
       " 0.9883399\n",
       " 0.9917211\n",
       " 0.97403437\n",
       " 0.9892775"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = [\"max_depth\" => 2,\n",
    "         \"eta\" => 1,\n",
    "         \"objective\" => \"binary:logistic\"]\n",
    "metrics = metrics = [\"error\", \"auc\"]\n",
    "model = xgboost(DMatrix(train_input, label=train_output_asNumber), rounds=20, param=param, metrics=metrics)\n",
    "\n",
    "pred = predict(model, train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120deba",
   "metadata": {},
   "source": [
    "***Important***.\n",
    "\n",
    "In case a validation set is used, this must be passed in the *evals* parameter of the training function. In addition, and only when the mentioned *evals* parameter is defined, you can set the rounds for the pre-stop with the *early_stopping_rounds* parameter of the training function. The code would be similar to:\n",
    "``` julia\n",
    "    evals = DMatrix(val_input, label=val_output)\n",
    "    xgb_model = xgb.train(param, train_input, num_round,label = train_output_asNumber, evals=evals,\n",
    "                    early_stopping_rounds=10)\n",
    "```\n",
    "\n",
    "The value provided in the output corresponds to the sum of the outputs of the trees, being between 0 and 1 for membership of a given class. Since this is a binary class, simply set a limit of 0.5 to the output to determine what the answer is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a468354c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error of XGboost= 0.0\n"
     ]
    }
   ],
   "source": [
    "using XGBoost: predict as predict_xgb\n",
    "\n",
    "pred = predict_xgb(model, test_input)\n",
    "print(\"Error of XGboost= \", sum((pred .> 0.5) .!= test_output) / float(size(pred)[1]), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d26f2",
   "metadata": {},
   "source": [
    "Finally, as in the case of the Random Forest it is possible to identify the importance and paint it for each of the variables in the ranking. With the following code it is possible to see such a marker ordered in a ascendent way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74e86f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip510\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip510)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip511\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip510)\" d=\"\n",
       "M205.121 1423.18 L2352.76 1423.18 L2352.76 123.472 L205.121 123.472  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip512\">\n",
       "    <rect x=\"205\" y=\"123\" width=\"2149\" height=\"1301\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  265.903,1423.18 265.903,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  609.305,1423.18 609.305,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  952.707,1423.18 952.707,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1296.11,1423.18 1296.11,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1639.51,1423.18 1639.51,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1982.91,1423.18 1982.91,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2326.31,1423.18 2326.31,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  205.121,1423.18 2352.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  265.903,1423.18 265.903,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  609.305,1423.18 609.305,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  952.707,1423.18 952.707,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1296.11,1423.18 1296.11,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1639.51,1423.18 1639.51,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1982.91,1423.18 1982.91,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2326.31,1423.18 2326.31,1404.28 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip510)\" d=\"M265.903 1454.1 Q262.292 1454.1 260.463 1457.66 Q258.658 1461.2 258.658 1468.33 Q258.658 1475.44 260.463 1479.01 Q262.292 1482.55 265.903 1482.55 Q269.537 1482.55 271.343 1479.01 Q273.172 1475.44 273.172 1468.33 Q273.172 1461.2 271.343 1457.66 Q269.537 1454.1 265.903 1454.1 M265.903 1450.39 Q271.713 1450.39 274.769 1455 Q277.847 1459.58 277.847 1468.33 Q277.847 1477.06 274.769 1481.67 Q271.713 1486.25 265.903 1486.25 Q260.093 1486.25 257.014 1481.67 Q253.959 1477.06 253.959 1468.33 Q253.959 1459.58 257.014 1455 Q260.093 1450.39 265.903 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M583.993 1481.64 L591.631 1481.64 L591.631 1455.28 L583.321 1456.95 L583.321 1452.69 L591.585 1451.02 L596.261 1451.02 L596.261 1481.64 L603.9 1481.64 L603.9 1485.58 L583.993 1485.58 L583.993 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M623.344 1454.1 Q619.733 1454.1 617.904 1457.66 Q616.099 1461.2 616.099 1468.33 Q616.099 1475.44 617.904 1479.01 Q619.733 1482.55 623.344 1482.55 Q626.978 1482.55 628.784 1479.01 Q630.613 1475.44 630.613 1468.33 Q630.613 1461.2 628.784 1457.66 Q626.978 1454.1 623.344 1454.1 M623.344 1450.39 Q629.154 1450.39 632.21 1455 Q635.289 1459.58 635.289 1468.33 Q635.289 1477.06 632.21 1481.67 Q629.154 1486.25 623.344 1486.25 Q617.534 1486.25 614.455 1481.67 Q611.4 1477.06 611.4 1468.33 Q611.4 1459.58 614.455 1455 Q617.534 1450.39 623.344 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M931.48 1481.64 L947.799 1481.64 L947.799 1485.58 L925.855 1485.58 L925.855 1481.64 Q928.517 1478.89 933.1 1474.26 Q937.707 1469.61 938.887 1468.27 Q941.133 1465.74 942.012 1464.01 Q942.915 1462.25 942.915 1460.56 Q942.915 1457.8 940.971 1456.07 Q939.049 1454.33 935.948 1454.33 Q933.748 1454.33 931.295 1455.09 Q928.864 1455.86 926.086 1457.41 L926.086 1452.69 Q928.911 1451.55 931.364 1450.97 Q933.818 1450.39 935.855 1450.39 Q941.225 1450.39 944.42 1453.08 Q947.614 1455.77 947.614 1460.26 Q947.614 1462.39 946.804 1464.31 Q946.017 1466.2 943.91 1468.8 Q943.332 1469.47 940.23 1472.69 Q937.128 1475.88 931.48 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M967.614 1454.1 Q964.003 1454.1 962.174 1457.66 Q960.369 1461.2 960.369 1468.33 Q960.369 1475.44 962.174 1479.01 Q964.003 1482.55 967.614 1482.55 Q971.248 1482.55 973.054 1479.01 Q974.883 1475.44 974.883 1468.33 Q974.883 1461.2 973.054 1457.66 Q971.248 1454.1 967.614 1454.1 M967.614 1450.39 Q973.424 1450.39 976.48 1455 Q979.558 1459.58 979.558 1468.33 Q979.558 1477.06 976.48 1481.67 Q973.424 1486.25 967.614 1486.25 Q961.804 1486.25 958.725 1481.67 Q955.67 1477.06 955.67 1468.33 Q955.67 1459.58 958.725 1455 Q961.804 1450.39 967.614 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1284.95 1466.95 Q1288.31 1467.66 1290.18 1469.93 Q1292.08 1472.2 1292.08 1475.53 Q1292.08 1480.65 1288.56 1483.45 Q1285.04 1486.25 1278.56 1486.25 Q1276.39 1486.25 1274.07 1485.81 Q1271.78 1485.39 1269.33 1484.54 L1269.33 1480.02 Q1271.27 1481.16 1273.59 1481.74 Q1275.9 1482.32 1278.42 1482.32 Q1282.82 1482.32 1285.11 1480.58 Q1287.43 1478.84 1287.43 1475.53 Q1287.43 1472.48 1285.28 1470.77 Q1283.15 1469.03 1279.33 1469.03 L1275.3 1469.03 L1275.3 1465.19 L1279.51 1465.19 Q1282.96 1465.19 1284.79 1463.82 Q1286.62 1462.43 1286.62 1459.84 Q1286.62 1457.18 1284.72 1455.77 Q1282.84 1454.33 1279.33 1454.33 Q1277.4 1454.33 1275.21 1454.75 Q1273.01 1455.16 1270.37 1456.04 L1270.37 1451.88 Q1273.03 1451.14 1275.34 1450.77 Q1277.68 1450.39 1279.74 1450.39 Q1285.07 1450.39 1288.17 1452.83 Q1291.27 1455.23 1291.27 1459.35 Q1291.27 1462.22 1289.63 1464.21 Q1287.98 1466.18 1284.95 1466.95 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1310.95 1454.1 Q1307.34 1454.1 1305.51 1457.66 Q1303.7 1461.2 1303.7 1468.33 Q1303.7 1475.44 1305.51 1479.01 Q1307.34 1482.55 1310.95 1482.55 Q1314.58 1482.55 1316.39 1479.01 Q1318.21 1475.44 1318.21 1468.33 Q1318.21 1461.2 1316.39 1457.66 Q1314.58 1454.1 1310.95 1454.1 M1310.95 1450.39 Q1316.76 1450.39 1319.81 1455 Q1322.89 1459.58 1322.89 1468.33 Q1322.89 1477.06 1319.81 1481.67 Q1316.76 1486.25 1310.95 1486.25 Q1305.14 1486.25 1302.06 1481.67 Q1299 1477.06 1299 1468.33 Q1299 1459.58 1302.06 1455 Q1305.14 1450.39 1310.95 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1627.68 1455.09 L1615.88 1473.54 L1627.68 1473.54 L1627.68 1455.09 M1626.45 1451.02 L1632.33 1451.02 L1632.33 1473.54 L1637.26 1473.54 L1637.26 1477.43 L1632.33 1477.43 L1632.33 1485.58 L1627.68 1485.58 L1627.68 1477.43 L1612.08 1477.43 L1612.08 1472.92 L1626.45 1451.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1655 1454.1 Q1651.39 1454.1 1649.56 1457.66 Q1647.75 1461.2 1647.75 1468.33 Q1647.75 1475.44 1649.56 1479.01 Q1651.39 1482.55 1655 1482.55 Q1658.63 1482.55 1660.44 1479.01 Q1662.26 1475.44 1662.26 1468.33 Q1662.26 1461.2 1660.44 1457.66 Q1658.63 1454.1 1655 1454.1 M1655 1450.39 Q1660.81 1450.39 1663.86 1455 Q1666.94 1459.58 1666.94 1468.33 Q1666.94 1477.06 1663.86 1481.67 Q1660.81 1486.25 1655 1486.25 Q1649.19 1486.25 1646.11 1481.67 Q1643.05 1477.06 1643.05 1468.33 Q1643.05 1459.58 1646.11 1455 Q1649.19 1450.39 1655 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1957.61 1451.02 L1975.97 1451.02 L1975.97 1454.96 L1961.89 1454.96 L1961.89 1463.43 Q1962.91 1463.08 1963.93 1462.92 Q1964.95 1462.73 1965.97 1462.73 Q1971.75 1462.73 1975.13 1465.9 Q1978.51 1469.08 1978.51 1474.49 Q1978.51 1480.07 1975.04 1483.17 Q1971.57 1486.25 1965.25 1486.25 Q1963.07 1486.25 1960.81 1485.88 Q1958.56 1485.51 1956.15 1484.77 L1956.15 1480.07 Q1958.24 1481.2 1960.46 1481.76 Q1962.68 1482.32 1965.16 1482.32 Q1969.16 1482.32 1971.5 1480.21 Q1973.84 1478.1 1973.84 1474.49 Q1973.84 1470.88 1971.5 1468.77 Q1969.16 1466.67 1965.16 1466.67 Q1963.28 1466.67 1961.41 1467.08 Q1959.56 1467.5 1957.61 1468.38 L1957.61 1451.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1997.73 1454.1 Q1994.12 1454.1 1992.29 1457.66 Q1990.48 1461.2 1990.48 1468.33 Q1990.48 1475.44 1992.29 1479.01 Q1994.12 1482.55 1997.73 1482.55 Q2001.36 1482.55 2003.17 1479.01 Q2005 1475.44 2005 1468.33 Q2005 1461.2 2003.17 1457.66 Q2001.36 1454.1 1997.73 1454.1 M1997.73 1450.39 Q2003.54 1450.39 2006.59 1455 Q2009.67 1459.58 2009.67 1468.33 Q2009.67 1477.06 2006.59 1481.67 Q2003.54 1486.25 1997.73 1486.25 Q1991.92 1486.25 1988.84 1481.67 Q1985.78 1477.06 1985.78 1468.33 Q1985.78 1459.58 1988.84 1455 Q1991.92 1450.39 1997.73 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M2311.72 1466.44 Q2308.57 1466.44 2306.72 1468.59 Q2304.89 1470.74 2304.89 1474.49 Q2304.89 1478.22 2306.72 1480.39 Q2308.57 1482.55 2311.72 1482.55 Q2314.87 1482.55 2316.7 1480.39 Q2318.55 1478.22 2318.55 1474.49 Q2318.55 1470.74 2316.7 1468.59 Q2314.87 1466.44 2311.72 1466.44 M2321 1451.78 L2321 1456.04 Q2319.24 1455.21 2317.44 1454.77 Q2315.65 1454.33 2313.9 1454.33 Q2309.27 1454.33 2306.81 1457.45 Q2304.38 1460.58 2304.03 1466.9 Q2305.4 1464.89 2307.46 1463.82 Q2309.52 1462.73 2312 1462.73 Q2317.21 1462.73 2320.21 1465.9 Q2323.25 1469.05 2323.25 1474.49 Q2323.25 1479.82 2320.1 1483.03 Q2316.95 1486.25 2311.72 1486.25 Q2305.72 1486.25 2302.55 1481.67 Q2299.38 1477.06 2299.38 1468.33 Q2299.38 1460.14 2303.27 1455.28 Q2307.16 1450.39 2313.71 1450.39 Q2315.47 1450.39 2317.25 1450.74 Q2319.06 1451.09 2321 1451.78 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M2341.3 1454.1 Q2337.69 1454.1 2335.86 1457.66 Q2334.06 1461.2 2334.06 1468.33 Q2334.06 1475.44 2335.86 1479.01 Q2337.69 1482.55 2341.3 1482.55 Q2344.94 1482.55 2346.74 1479.01 Q2348.57 1475.44 2348.57 1468.33 Q2348.57 1461.2 2346.74 1457.66 Q2344.94 1454.1 2341.3 1454.1 M2341.3 1450.39 Q2347.11 1450.39 2350.17 1455 Q2353.25 1459.58 2353.25 1468.33 Q2353.25 1477.06 2350.17 1481.67 Q2347.11 1486.25 2341.3 1486.25 Q2335.49 1486.25 2332.41 1481.67 Q2329.36 1477.06 2329.36 1468.33 Q2329.36 1459.58 2332.41 1455 Q2335.49 1450.39 2341.3 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1243.74 1561.26 L1243.74 1548.5 L1233.23 1548.5 L1233.23 1543.22 L1250.1 1543.22 L1250.1 1563.62 Q1246.38 1566.26 1241.89 1567.63 Q1237.4 1568.97 1232.31 1568.97 Q1221.17 1568.97 1214.87 1562.47 Q1208.6 1555.95 1208.6 1544.33 Q1208.6 1532.68 1214.87 1526.19 Q1221.17 1519.66 1232.31 1519.66 Q1236.96 1519.66 1241.13 1520.81 Q1245.33 1521.96 1248.86 1524.18 L1248.86 1531.03 Q1245.3 1528 1241.29 1526.48 Q1237.27 1524.95 1232.85 1524.95 Q1224.13 1524.95 1219.74 1529.82 Q1215.38 1534.69 1215.38 1544.33 Q1215.38 1553.94 1219.74 1558.81 Q1224.13 1563.68 1232.85 1563.68 Q1236.26 1563.68 1238.93 1563.11 Q1241.6 1562.51 1243.74 1561.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1277.79 1550.12 Q1270.69 1550.12 1267.96 1551.75 Q1265.22 1553.37 1265.22 1557.29 Q1265.22 1560.4 1267.26 1562.25 Q1269.33 1564.07 1272.86 1564.07 Q1277.73 1564.07 1280.66 1560.63 Q1283.62 1557.16 1283.62 1551.43 L1283.62 1550.12 L1277.79 1550.12 M1289.47 1547.71 L1289.47 1568.04 L1283.62 1568.04 L1283.62 1562.63 Q1281.61 1565.88 1278.62 1567.44 Q1275.63 1568.97 1271.3 1568.97 Q1265.83 1568.97 1262.58 1565.91 Q1259.36 1562.82 1259.36 1557.67 Q1259.36 1551.65 1263.37 1548.6 Q1267.42 1545.54 1275.41 1545.54 L1283.62 1545.54 L1283.62 1544.97 Q1283.62 1540.93 1280.94 1538.73 Q1278.3 1536.5 1273.5 1536.5 Q1270.44 1536.5 1267.54 1537.23 Q1264.65 1537.97 1261.97 1539.43 L1261.97 1534.02 Q1265.19 1532.78 1268.21 1532.17 Q1271.24 1531.54 1274.1 1531.54 Q1281.83 1531.54 1285.65 1535.55 Q1289.47 1539.56 1289.47 1547.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1301.54 1532.4 L1307.39 1532.4 L1307.39 1568.04 L1301.54 1568.04 L1301.54 1532.4 M1301.54 1518.52 L1307.39 1518.52 L1307.39 1525.93 L1301.54 1525.93 L1301.54 1518.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1349.28 1546.53 L1349.28 1568.04 L1343.42 1568.04 L1343.42 1546.72 Q1343.42 1541.66 1341.45 1539.14 Q1339.48 1536.63 1335.53 1536.63 Q1330.79 1536.63 1328.05 1539.65 Q1325.31 1542.68 1325.31 1547.9 L1325.31 1568.04 L1319.42 1568.04 L1319.42 1532.4 L1325.31 1532.4 L1325.31 1537.93 Q1327.41 1534.72 1330.25 1533.13 Q1333.11 1531.54 1336.83 1531.54 Q1342.98 1531.54 1346.13 1535.36 Q1349.28 1539.14 1349.28 1546.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  205.121,1365.36 2352.76,1365.36 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  205.121,1137.65 2352.76,1137.65 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  205.121,909.948 2352.76,909.948 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  205.121,682.244 2352.76,682.244 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  205.121,454.541 2352.76,454.541 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  205.121,226.837 2352.76,226.837 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  205.121,1423.18 205.121,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  205.121,1365.36 224.019,1365.36 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  205.121,1137.65 224.019,1137.65 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  205.121,909.948 224.019,909.948 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  205.121,682.244 224.019,682.244 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  205.121,454.541 224.019,454.541 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip510)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  205.121,226.837 224.019,226.837 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip510)\" d=\"M157.177 1351.15 Q153.566 1351.15 151.737 1354.72 Q149.931 1358.26 149.931 1365.39 Q149.931 1372.5 151.737 1376.06 Q153.566 1379.6 157.177 1379.6 Q160.811 1379.6 162.616 1376.06 Q164.445 1372.5 164.445 1365.39 Q164.445 1358.26 162.616 1354.72 Q160.811 1351.15 157.177 1351.15 M157.177 1347.45 Q162.987 1347.45 166.042 1352.06 Q169.121 1356.64 169.121 1365.39 Q169.121 1374.12 166.042 1378.72 Q162.987 1383.31 157.177 1383.31 Q151.366 1383.31 148.288 1378.72 Q145.232 1374.12 145.232 1365.39 Q145.232 1356.64 148.288 1352.06 Q151.366 1347.45 157.177 1347.45 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M117.825 1151 L125.464 1151 L125.464 1124.63 L117.154 1126.3 L117.154 1122.04 L125.418 1120.37 L130.093 1120.37 L130.093 1151 L137.732 1151 L137.732 1154.93 L117.825 1154.93 L117.825 1151 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M157.177 1123.45 Q153.566 1123.45 151.737 1127.02 Q149.931 1130.56 149.931 1137.69 Q149.931 1144.79 151.737 1148.36 Q153.566 1151.9 157.177 1151.9 Q160.811 1151.9 162.616 1148.36 Q164.445 1144.79 164.445 1137.69 Q164.445 1130.56 162.616 1127.02 Q160.811 1123.45 157.177 1123.45 M157.177 1119.75 Q162.987 1119.75 166.042 1124.35 Q169.121 1128.94 169.121 1137.69 Q169.121 1146.41 166.042 1151.02 Q162.987 1155.6 157.177 1155.6 Q151.366 1155.6 148.288 1151.02 Q145.232 1146.41 145.232 1137.69 Q145.232 1128.94 148.288 1124.35 Q151.366 1119.75 157.177 1119.75 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M121.043 923.293 L137.362 923.293 L137.362 927.228 L115.418 927.228 L115.418 923.293 Q118.08 920.538 122.663 915.909 Q127.269 911.256 128.45 909.914 Q130.695 907.39 131.575 905.654 Q132.478 903.895 132.478 902.205 Q132.478 899.451 130.533 897.715 Q128.612 895.978 125.51 895.978 Q123.311 895.978 120.857 896.742 Q118.427 897.506 115.649 899.057 L115.649 894.335 Q118.473 893.201 120.927 892.622 Q123.38 892.043 125.418 892.043 Q130.788 892.043 133.982 894.728 Q137.177 897.414 137.177 901.904 Q137.177 904.034 136.367 905.955 Q135.579 907.853 133.473 910.446 Q132.894 911.117 129.792 914.335 Q126.691 917.529 121.043 923.293 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M157.177 895.747 Q153.566 895.747 151.737 899.312 Q149.931 902.853 149.931 909.983 Q149.931 917.089 151.737 920.654 Q153.566 924.196 157.177 924.196 Q160.811 924.196 162.616 920.654 Q164.445 917.089 164.445 909.983 Q164.445 902.853 162.616 899.312 Q160.811 895.747 157.177 895.747 M157.177 892.043 Q162.987 892.043 166.042 896.65 Q169.121 901.233 169.121 909.983 Q169.121 918.71 166.042 923.316 Q162.987 927.9 157.177 927.9 Q151.366 927.9 148.288 923.316 Q145.232 918.71 145.232 909.983 Q145.232 901.233 148.288 896.65 Q151.366 892.043 157.177 892.043 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M131.181 680.89 Q134.538 681.608 136.413 683.876 Q138.311 686.145 138.311 689.478 Q138.311 694.594 134.792 697.395 Q131.274 700.196 124.793 700.196 Q122.617 700.196 120.302 699.756 Q118.01 699.339 115.556 698.483 L115.556 693.969 Q117.501 695.103 119.816 695.682 Q122.13 696.261 124.654 696.261 Q129.052 696.261 131.343 694.524 Q133.658 692.788 133.658 689.478 Q133.658 686.423 131.505 684.71 Q129.376 682.974 125.556 682.974 L121.529 682.974 L121.529 679.131 L125.742 679.131 Q129.191 679.131 131.019 677.765 Q132.848 676.376 132.848 673.784 Q132.848 671.122 130.95 669.71 Q129.075 668.275 125.556 668.275 Q123.635 668.275 121.436 668.691 Q119.237 669.108 116.598 669.988 L116.598 665.821 Q119.26 665.08 121.575 664.71 Q123.913 664.339 125.973 664.339 Q131.297 664.339 134.399 666.77 Q137.501 669.177 137.501 673.298 Q137.501 676.168 135.857 678.159 Q134.214 680.126 131.181 680.89 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M157.177 668.043 Q153.566 668.043 151.737 671.608 Q149.931 675.15 149.931 682.279 Q149.931 689.386 151.737 692.95 Q153.566 696.492 157.177 696.492 Q160.811 696.492 162.616 692.95 Q164.445 689.386 164.445 682.279 Q164.445 675.15 162.616 671.608 Q160.811 668.043 157.177 668.043 M157.177 664.339 Q162.987 664.339 166.042 668.946 Q169.121 673.529 169.121 682.279 Q169.121 691.006 166.042 695.612 Q162.987 700.196 157.177 700.196 Q151.366 700.196 148.288 695.612 Q145.232 691.006 145.232 682.279 Q145.232 673.529 148.288 668.946 Q151.366 664.339 157.177 664.339 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M129.862 441.335 L118.056 459.784 L129.862 459.784 L129.862 441.335 M128.635 437.261 L134.515 437.261 L134.515 459.784 L139.445 459.784 L139.445 463.673 L134.515 463.673 L134.515 471.821 L129.862 471.821 L129.862 463.673 L114.26 463.673 L114.26 459.159 L128.635 437.261 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M157.177 440.339 Q153.566 440.339 151.737 443.904 Q149.931 447.446 149.931 454.575 Q149.931 461.682 151.737 465.247 Q153.566 468.788 157.177 468.788 Q160.811 468.788 162.616 465.247 Q164.445 461.682 164.445 454.575 Q164.445 447.446 162.616 443.904 Q160.811 440.339 157.177 440.339 M157.177 436.636 Q162.987 436.636 166.042 441.242 Q169.121 445.825 169.121 454.575 Q169.121 463.302 166.042 467.909 Q162.987 472.492 157.177 472.492 Q151.366 472.492 148.288 467.909 Q145.232 463.302 145.232 454.575 Q145.232 445.825 148.288 441.242 Q151.366 436.636 157.177 436.636 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M117.061 209.557 L135.417 209.557 L135.417 213.492 L121.343 213.492 L121.343 221.964 Q122.362 221.617 123.38 221.455 Q124.399 221.27 125.418 221.27 Q131.205 221.27 134.584 224.441 Q137.964 227.612 137.964 233.029 Q137.964 238.608 134.492 241.709 Q131.019 244.788 124.7 244.788 Q122.524 244.788 120.255 244.418 Q118.01 244.047 115.603 243.307 L115.603 238.608 Q117.686 239.742 119.908 240.297 Q122.13 240.853 124.607 240.853 Q128.612 240.853 130.95 238.747 Q133.288 236.64 133.288 233.029 Q133.288 229.418 130.95 227.311 Q128.612 225.205 124.607 225.205 Q122.732 225.205 120.857 225.622 Q119.006 226.038 117.061 226.918 L117.061 209.557 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M157.177 212.636 Q153.566 212.636 151.737 216.2 Q149.931 219.742 149.931 226.872 Q149.931 233.978 151.737 237.543 Q153.566 241.085 157.177 241.085 Q160.811 241.085 162.616 237.543 Q164.445 233.978 164.445 226.872 Q164.445 219.742 162.616 216.2 Q160.811 212.636 157.177 212.636 M157.177 208.932 Q162.987 208.932 166.042 213.538 Q169.121 218.122 169.121 226.872 Q169.121 235.598 166.042 240.205 Q162.987 244.788 157.177 244.788 Q151.366 244.788 148.288 240.205 Q145.232 235.598 145.232 226.872 Q145.232 218.122 148.288 213.538 Q151.366 208.932 157.177 208.932 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M16.4842 891.553 L16.4842 864.244 L21.895 864.244 L21.895 885.124 L35.8996 885.124 L35.8996 866.281 L41.3104 866.281 L41.3104 885.124 L64.0042 885.124 L64.0042 891.553 L16.4842 891.553 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M44.7161 827.387 L47.5806 827.387 L47.5806 854.314 Q53.6281 853.932 56.8109 850.685 Q59.9619 847.407 59.9619 841.582 Q59.9619 838.208 59.1344 835.057 Q58.3069 831.875 56.6518 828.755 L62.1899 828.755 Q63.5267 831.906 64.227 835.217 Q64.9272 838.527 64.9272 841.932 Q64.9272 850.462 59.9619 855.46 Q54.9967 860.425 46.5303 860.425 Q37.7774 860.425 32.6531 855.714 Q27.4968 850.972 27.4968 842.951 Q27.4968 835.758 32.1438 831.588 Q36.7589 827.387 44.7161 827.387 M42.9973 833.243 Q38.1912 833.307 35.3266 835.949 Q32.4621 838.559 32.4621 842.887 Q32.4621 847.789 35.2312 850.749 Q38.0002 853.677 43.0292 854.123 L42.9973 833.243 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M46.0847 801.574 Q46.0847 808.672 47.7079 811.409 Q49.3312 814.146 53.2461 814.146 Q56.3653 814.146 58.2114 812.109 Q60.0256 810.04 60.0256 806.507 Q60.0256 801.637 56.5881 798.709 Q53.1188 795.749 47.3897 795.749 L46.0847 795.749 L46.0847 801.574 M43.6657 789.893 L64.0042 789.893 L64.0042 795.749 L58.5933 795.749 Q61.8398 797.754 63.3994 800.746 Q64.9272 803.738 64.9272 808.067 Q64.9272 813.541 61.8716 816.788 Q58.7843 820.003 53.6281 820.003 Q47.6125 820.003 44.5569 815.992 Q41.5014 811.95 41.5014 803.961 L41.5014 795.749 L40.9285 795.749 Q36.8862 795.749 34.6901 798.423 Q32.4621 801.065 32.4621 805.871 Q32.4621 808.926 33.1941 811.823 Q33.9262 814.719 35.3903 817.393 L29.9795 817.393 Q28.7381 814.178 28.1334 811.154 Q27.4968 808.13 27.4968 805.266 Q27.4968 797.532 31.5072 793.712 Q35.5176 789.893 43.6657 789.893 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M18.2347 772.037 L28.3562 772.037 L28.3562 759.974 L32.9077 759.974 L32.9077 772.037 L52.2594 772.037 Q56.6199 772.037 57.8613 770.859 Q59.1026 769.65 59.1026 765.99 L59.1026 759.974 L64.0042 759.974 L64.0042 765.99 Q64.0042 772.769 61.4897 775.347 Q58.9434 777.925 52.2594 777.925 L32.9077 777.925 L32.9077 782.222 L28.3562 782.222 L28.3562 777.925 L18.2347 777.925 L18.2347 772.037 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M49.9359 752.876 L28.3562 752.876 L28.3562 747.02 L49.7131 747.02 Q54.7739 747.02 57.3202 745.046 Q59.8346 743.073 59.8346 739.126 Q59.8346 734.384 56.8109 731.647 Q53.7872 728.877 48.5673 728.877 L28.3562 728.877 L28.3562 723.021 L64.0042 723.021 L64.0042 728.877 L58.5296 728.877 Q61.7762 731.01 63.3676 733.843 Q64.9272 736.644 64.9272 740.368 Q64.9272 746.51 61.1078 749.693 Q57.2883 752.876 49.9359 752.876 M27.4968 738.14 L27.4968 738.14 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M33.8307 690.301 Q33.2578 691.288 33.0032 692.466 Q32.7167 693.611 32.7167 695.012 Q32.7167 699.977 35.9632 702.651 Q39.1779 705.292 45.2253 705.292 L64.0042 705.292 L64.0042 711.181 L28.3562 711.181 L28.3562 705.292 L33.8944 705.292 Q30.6479 703.446 29.0883 700.486 Q27.4968 697.526 27.4968 693.293 Q27.4968 692.688 27.5923 691.956 Q27.656 691.224 27.8151 690.333 L33.8307 690.301 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M44.7161 655.099 L47.5806 655.099 L47.5806 682.026 Q53.6281 681.644 56.8109 678.397 Q59.9619 675.119 59.9619 669.294 Q59.9619 665.921 59.1344 662.77 Q58.3069 659.587 56.6518 656.468 L62.1899 656.468 Q63.5267 659.619 64.227 662.929 Q64.9272 666.239 64.9272 669.645 Q64.9272 678.175 59.9619 683.172 Q54.9967 688.137 46.5303 688.137 Q37.7774 688.137 32.6531 683.426 Q27.4968 678.684 27.4968 670.663 Q27.4968 663.47 32.1438 659.3 Q36.7589 655.099 44.7161 655.099 M42.9973 660.955 Q38.1912 661.019 35.3266 663.661 Q32.4621 666.271 32.4621 670.599 Q32.4621 675.501 35.2312 678.461 Q38.0002 681.389 43.0292 681.835 L42.9973 660.955 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M877.575 12.096 L912.332 12.096 L912.332 18.9825 L885.758 18.9825 L885.758 36.8065 L909.739 36.8065 L909.739 43.6931 L885.758 43.6931 L885.758 72.576 L877.575 72.576 L877.575 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M959.241 48.0275 L959.241 51.6733 L924.97 51.6733 Q925.457 59.3701 929.588 63.421 Q933.761 67.4314 941.174 67.4314 Q945.468 67.4314 949.478 66.3781 Q953.529 65.3249 957.499 63.2184 L957.499 70.267 Q953.489 71.9684 949.276 72.8596 Q945.063 73.7508 940.728 73.7508 Q929.872 73.7508 923.512 67.4314 Q917.193 61.1119 917.193 50.3365 Q917.193 39.1965 923.188 32.6746 Q929.224 26.1121 939.432 26.1121 Q948.587 26.1121 953.894 32.0264 Q959.241 37.9003 959.241 48.0275 M951.787 45.84 Q951.706 39.7232 948.344 36.0774 Q945.022 32.4315 939.513 32.4315 Q933.275 32.4315 929.507 35.9558 Q925.781 39.4801 925.213 45.8805 L951.787 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M992.094 49.7694 Q983.06 49.7694 979.577 51.8354 Q976.093 53.9013 976.093 58.8839 Q976.093 62.8538 978.685 65.2034 Q981.319 67.5124 985.815 67.5124 Q992.013 67.5124 995.74 63.1374 Q999.507 58.7219 999.507 51.4303 L999.507 49.7694 L992.094 49.7694 M1006.96 46.6907 L1006.96 72.576 L999.507 72.576 L999.507 65.6895 Q996.955 69.8214 993.147 71.8063 Q989.339 73.7508 983.83 73.7508 Q976.863 73.7508 972.731 69.8619 Q968.639 65.9325 968.639 59.3701 Q968.639 51.7138 973.743 47.825 Q978.888 43.9361 989.056 43.9361 L999.507 43.9361 L999.507 43.2069 Q999.507 38.0623 996.104 35.2672 Q992.742 32.4315 986.625 32.4315 Q982.736 32.4315 979.05 33.3632 Q975.364 34.295 971.961 36.1584 L971.961 29.2718 Q976.052 27.692 979.901 26.9223 Q983.749 26.1121 987.395 26.1121 Q997.239 26.1121 1002.1 31.2163 Q1006.96 36.3204 1006.96 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1029.69 14.324 L1029.69 27.2059 L1045.04 27.2059 L1045.04 32.9987 L1029.69 32.9987 L1029.69 57.6282 Q1029.69 63.1779 1031.19 64.7578 Q1032.72 66.3376 1037.38 66.3376 L1045.04 66.3376 L1045.04 72.576 L1037.38 72.576 Q1028.75 72.576 1025.47 69.3758 Q1022.19 66.1351 1022.19 57.6282 L1022.19 32.9987 L1016.72 32.9987 L1016.72 27.2059 L1022.19 27.2059 L1022.19 14.324 L1029.69 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1054.07 54.671 L1054.07 27.2059 L1061.53 27.2059 L1061.53 54.3874 Q1061.53 60.8284 1064.04 64.0691 Q1066.55 67.2693 1071.57 67.2693 Q1077.61 67.2693 1081.09 63.421 Q1084.62 59.5726 1084.62 52.9291 L1084.62 27.2059 L1092.07 27.2059 L1092.07 72.576 L1084.62 72.576 L1084.62 65.6084 Q1081.9 69.7404 1078.3 71.7658 Q1074.73 73.7508 1069.99 73.7508 Q1062.17 73.7508 1058.12 68.8897 Q1054.07 64.0286 1054.07 54.671 M1072.83 26.1121 L1072.83 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1133.71 34.1734 Q1132.46 33.4443 1130.96 33.1202 Q1129.5 32.7556 1127.72 32.7556 Q1121.4 32.7556 1118 36.8875 Q1114.63 40.9789 1114.63 48.6757 L1114.63 72.576 L1107.14 72.576 L1107.14 27.2059 L1114.63 27.2059 L1114.63 34.2544 Q1116.98 30.1225 1120.75 28.1376 Q1124.52 26.1121 1129.91 26.1121 Q1130.68 26.1121 1131.61 26.2337 Q1132.54 26.3147 1133.67 26.5172 L1133.71 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1178.52 48.0275 L1178.52 51.6733 L1144.25 51.6733 Q1144.73 59.3701 1148.86 63.421 Q1153.04 67.4314 1160.45 67.4314 Q1164.74 67.4314 1168.75 66.3781 Q1172.8 65.3249 1176.77 63.2184 L1176.77 70.267 Q1172.76 71.9684 1168.55 72.8596 Q1164.34 73.7508 1160 73.7508 Q1149.15 73.7508 1142.79 67.4314 Q1136.47 61.1119 1136.47 50.3365 Q1136.47 39.1965 1142.46 32.6746 Q1148.5 26.1121 1158.71 26.1121 Q1167.86 26.1121 1173.17 32.0264 Q1178.52 37.9003 1178.52 48.0275 M1171.06 45.84 Q1170.98 39.7232 1167.62 36.0774 Q1164.3 32.4315 1158.79 32.4315 Q1152.55 32.4315 1148.78 35.9558 Q1145.06 39.4801 1144.49 45.8805 L1171.06 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1217.45 12.096 L1225.63 12.096 L1225.63 72.576 L1217.45 72.576 L1217.45 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1276.91 35.9153 Q1279.71 30.8922 1283.6 28.5022 Q1287.49 26.1121 1292.75 26.1121 Q1299.84 26.1121 1303.69 31.0947 Q1307.54 36.0368 1307.54 45.1919 L1307.54 72.576 L1300.04 72.576 L1300.04 45.4349 Q1300.04 38.913 1297.73 35.7533 Q1295.43 32.5936 1290.69 32.5936 Q1284.89 32.5936 1281.53 36.4419 Q1278.17 40.2903 1278.17 46.9338 L1278.17 72.576 L1270.67 72.576 L1270.67 45.4349 Q1270.67 38.8725 1268.37 35.7533 Q1266.06 32.5936 1261.24 32.5936 Q1255.52 32.5936 1252.16 36.4824 Q1248.8 40.3308 1248.8 46.9338 L1248.8 72.576 L1241.31 72.576 L1241.31 27.2059 L1248.8 27.2059 L1248.8 34.2544 Q1251.35 30.082 1254.92 28.0971 Q1258.48 26.1121 1263.38 26.1121 Q1268.33 26.1121 1271.77 28.6237 Q1275.25 31.1352 1276.91 35.9153 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1329.62 65.7705 L1329.62 89.8329 L1322.12 89.8329 L1322.12 27.2059 L1329.62 27.2059 L1329.62 34.0924 Q1331.96 30.0415 1335.53 28.0971 Q1339.13 26.1121 1344.12 26.1121 Q1352.38 26.1121 1357.53 32.6746 Q1362.71 39.2371 1362.71 49.9314 Q1362.71 60.6258 1357.53 67.1883 Q1352.38 73.7508 1344.12 73.7508 Q1339.13 73.7508 1335.53 71.8063 Q1331.96 69.8214 1329.62 65.7705 M1354.97 49.9314 Q1354.97 41.7081 1351.57 37.0496 Q1348.21 32.3505 1342.29 32.3505 Q1336.38 32.3505 1332.98 37.0496 Q1329.62 41.7081 1329.62 49.9314 Q1329.62 58.1548 1332.98 62.8538 Q1336.38 67.5124 1342.29 67.5124 Q1348.21 67.5124 1351.57 62.8538 Q1354.97 58.1548 1354.97 49.9314 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1392.65 32.4315 Q1386.65 32.4315 1383.17 37.1306 Q1379.68 41.7891 1379.68 49.9314 Q1379.68 58.0738 1383.13 62.7728 Q1386.61 67.4314 1392.65 67.4314 Q1398.6 67.4314 1402.09 62.7323 Q1405.57 58.0333 1405.57 49.9314 Q1405.57 41.8701 1402.09 37.1711 Q1398.6 32.4315 1392.65 32.4315 M1392.65 26.1121 Q1402.37 26.1121 1407.92 32.4315 Q1413.47 38.7509 1413.47 49.9314 Q1413.47 61.0714 1407.92 67.4314 Q1402.37 73.7508 1392.65 73.7508 Q1382.88 73.7508 1377.33 67.4314 Q1371.83 61.0714 1371.83 49.9314 Q1371.83 38.7509 1377.33 32.4315 Q1382.88 26.1121 1392.65 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1452.11 34.1734 Q1450.86 33.4443 1449.36 33.1202 Q1447.9 32.7556 1446.12 32.7556 Q1439.8 32.7556 1436.4 36.8875 Q1433.03 40.9789 1433.03 48.6757 L1433.03 72.576 L1425.54 72.576 L1425.54 27.2059 L1433.03 27.2059 L1433.03 34.2544 Q1435.38 30.1225 1439.15 28.1376 Q1442.92 26.1121 1448.31 26.1121 Q1449.08 26.1121 1450.01 26.2337 Q1450.94 26.3147 1452.07 26.5172 L1452.11 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1467.31 14.324 L1467.31 27.2059 L1482.66 27.2059 L1482.66 32.9987 L1467.31 32.9987 L1467.31 57.6282 Q1467.31 63.1779 1468.8 64.7578 Q1470.34 66.3376 1475 66.3376 L1482.66 66.3376 L1482.66 72.576 L1475 72.576 Q1466.37 72.576 1463.09 69.3758 Q1459.81 66.1351 1459.81 57.6282 L1459.81 32.9987 L1454.34 32.9987 L1454.34 27.2059 L1459.81 27.2059 L1459.81 14.324 L1467.31 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1513.08 49.7694 Q1504.05 49.7694 1500.56 51.8354 Q1497.08 53.9013 1497.08 58.8839 Q1497.08 62.8538 1499.67 65.2034 Q1502.31 67.5124 1506.8 67.5124 Q1513 67.5124 1516.73 63.1374 Q1520.49 58.7219 1520.49 51.4303 L1520.49 49.7694 L1513.08 49.7694 M1527.95 46.6907 L1527.95 72.576 L1520.49 72.576 L1520.49 65.6895 Q1517.94 69.8214 1514.13 71.8063 Q1510.33 73.7508 1504.82 73.7508 Q1497.85 73.7508 1493.72 69.8619 Q1489.63 65.9325 1489.63 59.3701 Q1489.63 51.7138 1494.73 47.825 Q1499.87 43.9361 1510.04 43.9361 L1520.49 43.9361 L1520.49 43.2069 Q1520.49 38.0623 1517.09 35.2672 Q1513.73 32.4315 1507.61 32.4315 Q1503.72 32.4315 1500.04 33.3632 Q1496.35 34.295 1492.95 36.1584 L1492.95 29.2718 Q1497.04 27.692 1500.89 26.9223 Q1504.74 26.1121 1508.38 26.1121 Q1518.23 26.1121 1523.09 31.2163 Q1527.95 36.3204 1527.95 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1581.01 45.1919 L1581.01 72.576 L1573.56 72.576 L1573.56 45.4349 Q1573.56 38.994 1571.05 35.7938 Q1568.54 32.5936 1563.51 32.5936 Q1557.48 32.5936 1553.99 36.4419 Q1550.51 40.2903 1550.51 46.9338 L1550.51 72.576 L1543.02 72.576 L1543.02 27.2059 L1550.51 27.2059 L1550.51 34.2544 Q1553.18 30.163 1556.79 28.1376 Q1560.44 26.1121 1565.18 26.1121 Q1572.99 26.1121 1577 30.9732 Q1581.01 35.7938 1581.01 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1628.53 28.9478 L1628.53 35.9153 Q1625.37 34.1734 1622.17 33.3227 Q1619.01 32.4315 1615.77 32.4315 Q1608.52 32.4315 1604.51 37.0496 Q1600.5 41.6271 1600.5 49.9314 Q1600.5 58.2358 1604.51 62.8538 Q1608.52 67.4314 1615.77 67.4314 Q1619.01 67.4314 1622.17 66.5807 Q1625.37 65.6895 1628.53 63.9476 L1628.53 70.8341 Q1625.41 72.2924 1622.05 73.0216 Q1618.73 73.7508 1614.96 73.7508 Q1604.71 73.7508 1598.68 67.3098 Q1592.64 60.8689 1592.64 49.9314 Q1592.64 38.832 1598.72 32.472 Q1604.83 26.1121 1615.45 26.1121 Q1618.89 26.1121 1622.17 26.8413 Q1625.45 27.5299 1628.53 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip510)\" d=\"M1680.3 48.0275 L1680.3 51.6733 L1646.03 51.6733 Q1646.52 59.3701 1650.65 63.421 Q1654.82 67.4314 1662.23 67.4314 Q1666.53 67.4314 1670.54 66.3781 Q1674.59 65.3249 1678.56 63.2184 L1678.56 70.267 Q1674.55 71.9684 1670.34 72.8596 Q1666.12 73.7508 1661.79 73.7508 Q1650.93 73.7508 1644.57 67.4314 Q1638.25 61.1119 1638.25 50.3365 Q1638.25 39.1965 1644.25 32.6746 Q1650.28 26.1121 1660.49 26.1121 Q1669.65 26.1121 1674.95 32.0264 Q1680.3 37.9003 1680.3 48.0275 M1672.85 45.84 Q1672.77 39.7232 1669.41 36.0774 Q1666.08 32.4315 1660.57 32.4315 Q1654.34 32.4315 1650.57 35.9558 Q1646.84 39.4801 1646.27 45.8805 L1672.85 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip512)\" d=\"\n",
       "M643.645 1351.69 L265.903 1351.69 L265.903 1333.48 L643.645 1333.48 L643.645 1351.69 L643.645 1351.69  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  643.645,1351.69 265.903,1351.69 265.903,1333.48 643.645,1333.48 643.645,1351.69 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1433.47 1328.92 L265.903 1328.92 L265.903 1310.71 L1433.47 1310.71 L1433.47 1328.92 L1433.47 1328.92  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1433.47,1328.92 265.903,1328.92 265.903,1310.71 1433.47,1310.71 1433.47,1328.92 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1330.45 1306.15 L265.903 1306.15 L265.903 1287.94 L1330.45 1287.94 L1330.45 1306.15 L1330.45 1306.15  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1330.45,1306.15 265.903,1306.15 265.903,1287.94 1330.45,1287.94 1330.45,1306.15 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M815.346 1283.38 L265.903 1283.38 L265.903 1265.17 L815.346 1265.17 L815.346 1283.38 L815.346 1283.38  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  815.346,1283.38 265.903,1283.38 265.903,1265.17 815.346,1265.17 815.346,1283.38 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M403.264 1260.61 L265.903 1260.61 L265.903 1242.4 L403.264 1242.4 L403.264 1260.61 L403.264 1260.61  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  403.264,1260.61 265.903,1260.61 265.903,1242.4 403.264,1242.4 403.264,1260.61 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1055.73 1237.84 L265.903 1237.84 L265.903 1219.63 L1055.73 1219.63 L1055.73 1237.84 L1055.73 1237.84  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1055.73,1237.84 265.903,1237.84 265.903,1219.63 1055.73,1219.63 1055.73,1237.84 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M2154.61 1215.07 L265.903 1215.07 L265.903 1196.86 L2154.61 1196.86 L2154.61 1215.07 L2154.61 1215.07  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2154.61,1215.07 265.903,1215.07 265.903,1196.86 2154.61,1196.86 2154.61,1215.07 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1227.43 1192.3 L265.903 1192.3 L265.903 1174.08 L1227.43 1174.08 L1227.43 1192.3 L1227.43 1192.3  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1227.43,1192.3 265.903,1192.3 265.903,1174.08 1227.43,1174.08 1227.43,1192.3 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1811.21 1169.53 L265.903 1169.53 L265.903 1151.31 L1811.21 1151.31 L1811.21 1169.53 L1811.21 1169.53  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1811.21,1169.53 265.903,1169.53 265.903,1151.31 1811.21,1151.31 1811.21,1169.53 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M677.985 1146.76 L265.903 1146.76 L265.903 1128.54 L677.985 1128.54 L677.985 1146.76 L677.985 1146.76  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  677.985,1146.76 265.903,1146.76 265.903,1128.54 677.985,1128.54 677.985,1146.76 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M781.006 1123.99 L265.903 1123.99 L265.903 1105.77 L781.006 1105.77 L781.006 1123.99 L781.006 1123.99  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  781.006,1123.99 265.903,1123.99 265.903,1105.77 781.006,1105.77 781.006,1123.99 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1639.51 1101.22 L265.903 1101.22 L265.903 1083 L1639.51 1083 L1639.51 1101.22 L1639.51 1101.22  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1639.51,1101.22 265.903,1101.22 265.903,1083 1639.51,1083 1639.51,1101.22 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M2051.59 1078.45 L265.903 1078.45 L265.903 1060.23 L2051.59 1060.23 L2051.59 1078.45 L2051.59 1078.45  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2051.59,1078.45 265.903,1078.45 265.903,1060.23 2051.59,1060.23 2051.59,1078.45 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1502.15 1055.68 L265.903 1055.68 L265.903 1037.46 L1502.15 1037.46 L1502.15 1055.68 L1502.15 1055.68  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1502.15,1055.68 265.903,1055.68 265.903,1037.46 1502.15,1037.46 1502.15,1055.68 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M574.965 1032.91 L265.903 1032.91 L265.903 1014.69 L574.965 1014.69 L574.965 1032.91 L574.965 1032.91  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  574.965,1032.91 265.903,1032.91 265.903,1014.69 574.965,1014.69 574.965,1032.91 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M987.047 1010.14 L265.903 1010.14 L265.903 991.922 L987.047 991.922 L987.047 1010.14 L987.047 1010.14  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  987.047,1010.14 265.903,1010.14 265.903,991.922 987.047,991.922 987.047,1010.14 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M884.026 987.368 L265.903 987.368 L265.903 969.151 L884.026 969.151 L884.026 987.368 L884.026 987.368  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  884.026,987.368 265.903,987.368 265.903,969.151 884.026,969.151 884.026,987.368 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M849.686 964.597 L265.903 964.597 L265.903 946.381 L849.686 946.381 L849.686 964.597 L849.686 964.597  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  849.686,964.597 265.903,964.597 265.903,946.381 849.686,946.381 849.686,964.597 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1193.09 941.827 L265.903 941.827 L265.903 923.61 L1193.09 923.61 L1193.09 941.827 L1193.09 941.827  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1193.09,941.827 265.903,941.827 265.903,923.61 1193.09,923.61 1193.09,941.827 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1914.23 919.056 L265.903 919.056 L265.903 900.84 L1914.23 900.84 L1914.23 919.056 L1914.23 919.056  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1914.23,919.056 265.903,919.056 265.903,900.84 1914.23,900.84 1914.23,919.056 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M437.604 896.286 L265.903 896.286 L265.903 878.07 L437.604 878.07 L437.604 896.286 L437.604 896.286  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  437.604,896.286 265.903,896.286 265.903,878.07 437.604,878.07 437.604,896.286 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M2017.25 873.516 L265.903 873.516 L265.903 855.299 L2017.25 855.299 L2017.25 873.516 L2017.25 873.516  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2017.25,873.516 265.903,873.516 265.903,855.299 2017.25,855.299 2017.25,873.516 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1776.87 850.745 L265.903 850.745 L265.903 832.529 L1776.87 832.529 L1776.87 850.745 L1776.87 850.745  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1776.87,850.745 265.903,850.745 265.903,832.529 1776.87,832.529 1776.87,850.745 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M334.583 827.975 L265.903 827.975 L265.903 809.759 L334.583 809.759 L334.583 827.975 L334.583 827.975  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  334.583,827.975 265.903,827.975 265.903,809.759 334.583,809.759 334.583,827.975 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M2257.63 805.205 L265.903 805.205 L265.903 786.988 L2257.63 786.988 L2257.63 805.205 L2257.63 805.205  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2257.63,805.205 265.903,805.205 265.903,786.988 2257.63,786.988 2257.63,805.205 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1879.89 782.434 L265.903 782.434 L265.903 764.218 L1879.89 764.218 L1879.89 782.434 L1879.89 782.434  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1879.89,782.434 265.903,782.434 265.903,764.218 1879.89,764.218 1879.89,782.434 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1742.53 759.664 L265.903 759.664 L265.903 741.447 L1742.53 741.447 L1742.53 759.664 L1742.53 759.664  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1742.53,759.664 265.903,759.664 265.903,741.447 1742.53,741.447 1742.53,759.664 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1708.19 736.893 L265.903 736.893 L265.903 718.677 L1708.19 718.677 L1708.19 736.893 L1708.19 736.893  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1708.19,736.893 265.903,736.893 265.903,718.677 1708.19,718.677 1708.19,736.893 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1536.49 714.123 L265.903 714.123 L265.903 695.907 L1536.49 695.907 L1536.49 714.123 L1536.49 714.123  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1536.49,714.123 265.903,714.123 265.903,695.907 1536.49,695.907 1536.49,714.123 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M368.924 691.353 L265.903 691.353 L265.903 673.136 L368.924 673.136 L368.924 691.353 L368.924 691.353  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  368.924,691.353 265.903,691.353 265.903,673.136 368.924,673.136 368.924,691.353 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M540.625 668.582 L265.903 668.582 L265.903 650.366 L540.625 650.366 L540.625 668.582 L540.625 668.582  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  540.625,668.582 265.903,668.582 265.903,650.366 540.625,650.366 540.625,668.582 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1296.11 645.812 L265.903 645.812 L265.903 627.596 L1296.11 627.596 L1296.11 645.812 L1296.11 645.812  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1296.11,645.812 265.903,645.812 265.903,627.596 1296.11,627.596 1296.11,645.812 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M712.325 623.041 L265.903 623.041 L265.903 604.825 L712.325 604.825 L712.325 623.041 L712.325 623.041  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  712.325,623.041 265.903,623.041 265.903,604.825 712.325,604.825 712.325,623.041 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M471.944 600.271 L265.903 600.271 L265.903 582.055 L471.944 582.055 L471.944 600.271 L471.944 600.271  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  471.944,600.271 265.903,600.271 265.903,582.055 471.944,582.055 471.944,600.271 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M2120.27 577.501 L265.903 577.501 L265.903 559.284 L2120.27 559.284 L2120.27 577.501 L2120.27 577.501  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2120.27,577.501 265.903,577.501 265.903,559.284 2120.27,559.284 2120.27,577.501 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M300.243 554.73 L265.903 554.73 L265.903 536.514 L300.243 536.514 L300.243 554.73 L300.243 554.73  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  300.243,554.73 265.903,554.73 265.903,536.514 300.243,536.514 300.243,554.73 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M952.707 531.96 L265.903 531.96 L265.903 513.744 L952.707 513.744 L952.707 531.96 L952.707 531.96  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  952.707,531.96 265.903,531.96 265.903,513.744 952.707,513.744 952.707,531.96 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M506.284 509.19 L265.903 509.19 L265.903 490.973 L506.284 490.973 L506.284 509.19 L506.284 509.19  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  506.284,509.19 265.903,509.19 265.903,490.973 506.284,490.973 506.284,509.19 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1021.39 486.419 L265.903 486.419 L265.903 468.203 L1021.39 468.203 L1021.39 486.419 L1021.39 486.419  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1021.39,486.419 265.903,486.419 265.903,468.203 1021.39,468.203 1021.39,486.419 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1845.55 463.649 L265.903 463.649 L265.903 445.433 L1845.55 445.433 L1845.55 463.649 L1845.55 463.649  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1845.55,463.649 265.903,463.649 265.903,445.433 1845.55,445.433 1845.55,463.649 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M746.666 440.878 L265.903 440.878 L265.903 422.662 L746.666 422.662 L746.666 440.878 L746.666 440.878  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  746.666,440.878 265.903,440.878 265.903,422.662 746.666,422.662 746.666,440.878 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1570.83 418.108 L265.903 418.108 L265.903 399.892 L1570.83 399.892 L1570.83 418.108 L1570.83 418.108  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1570.83,418.108 265.903,418.108 265.903,399.892 1570.83,399.892 1570.83,418.108 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1948.57 395.338 L265.903 395.338 L265.903 377.121 L1948.57 377.121 L1948.57 395.338 L1948.57 395.338  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1948.57,395.338 265.903,395.338 265.903,377.121 1948.57,377.121 1948.57,395.338 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1364.79 372.567 L265.903 372.567 L265.903 354.351 L1364.79 354.351 L1364.79 372.567 L1364.79 372.567  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1364.79,372.567 265.903,372.567 265.903,354.351 1364.79,354.351 1364.79,372.567 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M2223.29 349.797 L265.903 349.797 L265.903 331.581 L2223.29 331.581 L2223.29 349.797 L2223.29 349.797  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2223.29,349.797 265.903,349.797 265.903,331.581 2223.29,331.581 2223.29,349.797 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M2291.97 327.027 L265.903 327.027 L265.903 308.81 L2291.97 308.81 L2291.97 327.027 L2291.97 327.027  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2291.97,327.027 265.903,327.027 265.903,308.81 2291.97,308.81 2291.97,327.027 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1124.41 304.256 L265.903 304.256 L265.903 286.04 L1124.41 286.04 L1124.41 304.256 L1124.41 304.256  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1124.41,304.256 265.903,304.256 265.903,286.04 1124.41,286.04 1124.41,304.256 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1399.13 281.486 L265.903 281.486 L265.903 263.27 L1399.13 263.27 L1399.13 281.486 L1399.13 281.486  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1399.13,281.486 265.903,281.486 265.903,263.27 1399.13,263.27 1399.13,281.486 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M1467.81 258.715 L265.903 258.715 L265.903 240.499 L1467.81 240.499 L1467.81 258.715 L1467.81 258.715  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1467.81,258.715 265.903,258.715 265.903,240.499 1467.81,240.499 1467.81,258.715 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M918.367 235.945 L265.903 235.945 L265.903 217.729 L918.367 217.729 L918.367 235.945 L918.367 235.945  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  918.367,235.945 265.903,235.945 265.903,217.729 918.367,217.729 918.367,235.945 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip512)\" d=\"\n",
       "M609.305 213.175 L265.903 213.175 L265.903 194.958 L609.305 194.958 L609.305 213.175 L609.305 213.175  Z\n",
       "  \" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip512)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  609.305,213.175 265.903,213.175 265.903,194.958 609.305,194.958 609.305,213.175 \n",
       "  \"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"643.645\" cy=\"1342.59\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1433.47\" cy=\"1319.82\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1330.45\" cy=\"1297.04\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"815.346\" cy=\"1274.27\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"403.264\" cy=\"1251.5\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1055.73\" cy=\"1228.73\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2154.61\" cy=\"1205.96\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1227.43\" cy=\"1183.19\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1811.21\" cy=\"1160.42\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"677.985\" cy=\"1137.65\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"781.006\" cy=\"1114.88\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1639.51\" cy=\"1092.11\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2051.59\" cy=\"1069.34\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1502.15\" cy=\"1046.57\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"574.965\" cy=\"1023.8\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"987.047\" cy=\"1001.03\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"884.026\" cy=\"978.259\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"849.686\" cy=\"955.489\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1193.09\" cy=\"932.719\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1914.23\" cy=\"909.948\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"437.604\" cy=\"887.178\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2017.25\" cy=\"864.407\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1776.87\" cy=\"841.637\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"334.583\" cy=\"818.867\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2257.63\" cy=\"796.096\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1879.89\" cy=\"773.326\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1742.53\" cy=\"750.556\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1708.19\" cy=\"727.785\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1536.49\" cy=\"705.015\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"368.924\" cy=\"682.244\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"540.625\" cy=\"659.474\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1296.11\" cy=\"636.704\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"712.325\" cy=\"613.933\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"471.944\" cy=\"591.163\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2120.27\" cy=\"568.393\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"300.243\" cy=\"545.622\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"952.707\" cy=\"522.852\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"506.284\" cy=\"500.081\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1021.39\" cy=\"477.311\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1845.55\" cy=\"454.541\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"746.666\" cy=\"431.77\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1570.83\" cy=\"409\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1948.57\" cy=\"386.23\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1364.79\" cy=\"363.459\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2223.29\" cy=\"340.689\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"2291.97\" cy=\"317.918\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1124.41\" cy=\"295.148\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1399.13\" cy=\"272.378\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"1467.81\" cy=\"249.607\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"918.367\" cy=\"226.837\" r=\"2\"/>\n",
       "<circle clip-path=\"url(#clip512)\" style=\"fill:#009af9; stroke:none; fill-opacity:0\" cx=\"609.305\" cy=\"204.067\" r=\"2\"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_gain =  [(first(x),last(x)) for x in importance(model)]\n",
    "feature, gain = first.(feature_gain), last.(feature_gain)\n",
    "\n",
    "using Plots;\n",
    "\n",
    "p = bar(feature, y=gain, orientation=\"h\", legend=false)\n",
    "xlabel!(p,\"Gain\")\n",
    "ylabel!(p,\"Feature\")\n",
    "title!(\"Feature Importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533db36",
   "metadata": {},
   "source": [
    "As you can see, not all features has the same importance. It should be notice that the Feature axis identifies the position in the Vector  feature which is ordered by the gain value by default."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
